{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Testing CNN Backbone Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class densetFPN_121(nn.Module):\n",
    "    \"\"\" DenseNet121-based Feature Pyramid Network (FPN) for feature extraction. \n",
    "        Total number of parameters:  8232320 (8.23 million) \"\"\" \n",
    "    def __init__(self, weights='DEFAULT', common_channel_size=256, output_channel_size=256):\n",
    "        super(densetFPN_121, self).__init__()\n",
    "        original_densenet = models.densenet121(weights=weights)\n",
    "        \n",
    "        # Initial layers: extract features without modification\n",
    "        self.encoder = nn.ModuleList([\n",
    "            nn.Sequential(*list(original_densenet.features.children())[:6], nn.Dropout(0.4)),   # 128x12x12\n",
    "            nn.Sequential(*list(original_densenet.features.children())[6:8], nn.Dropout(0.4)),  # 256x6x6\n",
    "            nn.Sequential(*list(original_densenet.features.children())[8:10], nn.Dropout(0.4)), # 896x3x3\n",
    "            nn.Sequential(*list(original_densenet.features.children())[10:-1], nn.Dropout(0.4)) # 1920x3x3\n",
    "        ])\n",
    "        \n",
    "        # Define convolutional layers for adapting channel sizes\n",
    "        fpn_channels = [128, 256, 512, 1024]\n",
    "        self.adaptation_layers = nn.ModuleDict({\n",
    "            f'adapt{i+1}': nn.Conv2d(fpn_channels[i], common_channel_size, kernel_size=1)\n",
    "            for i in range(4)\n",
    "        })\n",
    "\n",
    "        # Define FPN layers\n",
    "        self.fpn = nn.ModuleDict({\n",
    "            f'fpn{i+1}': nn.Conv2d(common_channel_size, common_channel_size, kernel_size=1)\n",
    "            for i in range(3)\n",
    "        })\n",
    "\n",
    "        self.merge_layers = nn.Sequential(\n",
    "            nn.Conv2d(common_channel_size, output_channel_size, kernel_size=3), # kernel size 1 or 3\n",
    "            nn.BatchNorm2d(output_channel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4) # 0.2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        features = []\n",
    "        for encoder in self.encoder:\n",
    "            x = encoder(x)\n",
    "            features.append(x)\n",
    "        \n",
    "        # Merge channels using 1x1 convolutions\n",
    "        adapted_features = [self.adaptation_layers[f'adapt{i+1}'](features[i]) for i in range(4)]\n",
    "        \n",
    "        # FPN integration using top-down pathway\n",
    "        fpn_output = adapted_features.pop()  # Start with the deepest features\n",
    "        for i in reversed(range(3)):\n",
    "            upsampled = F.interpolate(fpn_output, size=adapted_features[i].shape[-2:], mode='nearest')\n",
    "            fpn_output = self.fpn[f'fpn{i+1}'](upsampled + adapted_features[i])\n",
    "        \n",
    "        # Merge features\n",
    "        merged_features = self.merge_layers(fpn_output)\n",
    "        \n",
    "        return merged_features\n",
    "\n",
    "\n",
    "model = densetFPN_121(weights=None)\n",
    "\n",
    "# Print total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total number of parameters: \", total_params)\n",
    "\n",
    "# Create a dummy input tensor of size [50, 3, 100, 100]\n",
    "dummy_input = torch.randn(50, 3, 100, 100)\n",
    "\n",
    "# Forward pass through the model with dummy input\n",
    "features = model(dummy_input)\n",
    "\n",
    "# Print output shapes to verify\n",
    "print(\"Features shape:\", features.shape)\n",
    "\n",
    "# print(features.conv_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "class efficientDecoder_v2_s(nn.Module):\n",
    "    def __init__(self, num_channels=[24, 48, 64, 128, 160, 256], output_channel_size=256, output_feature_size=25):\n",
    "        super(efficientDecoder_v2_s, self).__init__()\n",
    "        # Load EfficientNet V2 Small features\n",
    "        efficientnet_v2_s = models.efficientnet_v2_s(weights='DEFAULT').features[:-1]\n",
    "\n",
    "        # Modularize encoders\n",
    "        self.encoders = nn.ModuleList([\n",
    "            nn.Sequential(*list(efficientnet_v2_s.children())[:2], nn.Dropout(0.1)),    # 24x50x50\n",
    "            nn.Sequential(*list(efficientnet_v2_s.children())[2:3], nn.Dropout(0.1)),   # 48x25x25\n",
    "            nn.Sequential(*list(efficientnet_v2_s.children())[3:4], nn.Dropout(0.2)),   # 64x13x13\n",
    "            nn.Sequential(*list(efficientnet_v2_s.children())[4:5], nn.Dropout(0.2)),   # 128x7x7\n",
    "            nn.Sequential(*list(efficientnet_v2_s.children())[5:6], nn.Dropout(0.3)),   # 160x7x7 # TODO: Check whether to skip 128x7x7\n",
    "            nn.Sequential(*list(efficientnet_v2_s.children())[6:7], nn.Dropout(0.3))    # 256x4x4\n",
    "        ])\n",
    "        \n",
    "        # Modularize upconvolutions\n",
    "        self.upconvs = nn.ModuleList([\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=160, kernel_size=2, stride=2, padding=1, output_padding=1),\n",
    "            nn.Conv2d(in_channels=160, out_channels=128, kernel_size=1, stride=1),\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=2, padding=1, output_padding=1),\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=48, kernel_size=2, stride=2, padding=1, output_padding=1),\n",
    "            nn.ConvTranspose2d(in_channels=48, out_channels=24, kernel_size=2, stride=2)\n",
    "        ])\n",
    "        \n",
    "        # Modularize decoders\n",
    "        self.decoders = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(num_channels[i] * 2, num_channels[i], kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(num_channels[i]),\n",
    "                nn.SiLU(),\n",
    "                nn.Dropout(0.1 + i * 0.05)\n",
    "            ) for i in range(len(num_channels)-1)\n",
    "        ])\n",
    "\n",
    "        # Optional, merge layers to increase the number of channels\n",
    "        self.merge_layers = nn.Sequential(\n",
    "            nn.Conv2d(24, output_channel_size, kernel_size=1),\n",
    "            nn.BatchNorm2d(output_channel_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(output_feature_size) # to reduce noise and overfitting\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        features = []\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "            features.append(x)\n",
    "        \n",
    "        # Decoder\n",
    "        x = features.pop()\n",
    "        for upconv, decoder, feature in zip(self.upconvs, reversed(self.decoders), reversed(features)):\n",
    "            x = upconv(x)\n",
    "            x = torch.cat((x, feature), dim=1)\n",
    "            x = decoder(x)\n",
    "        \n",
    "        x = self.merge_layers(x) # Introduced to increase the number of channels\n",
    "        pooled_features = self.global_avg_pool(x) # Introduced to reduce noise and overfitting\n",
    "        \n",
    "        return pooled_features\n",
    "\n",
    "model = efficientDecoder_v2_s()\n",
    "\n",
    "# Print total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total number of parameters: \", total_params)\n",
    "\n",
    "# Create a dummy input tensor of size [50, 3, 100, 100]\n",
    "dummy_input = torch.randn(50, 3, 100, 100)\n",
    "\n",
    "# Forward pass through the model with dummy input\n",
    "features = model(dummy_input)\n",
    "\n",
    "# Print output shapes to verify\n",
    "print(\"Features shape:\", features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in reversed(range(1,6)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class efficientDecoder_v2_s(nn.Module):\n",
    "    def __init__(self, output_channel_size=256, output_feature_size=25):\n",
    "        super(efficientDecoder_v2_s, self).__init__()\n",
    "        # Load EfficientNet V2 Small features\n",
    "        efficientnet_v2_s = models.efficientnet_v2_s(weights='DEFAULT').features[:-1]\n",
    "\n",
    "        # Modularize encoders\n",
    "        self.encoders = nn.ModuleList([\n",
    "            nn.Sequential(*list(efficientnet_v2_s.children())[:2], nn.Dropout(0.1)),    # 24x50x50\n",
    "            nn.Sequential(*list(efficientnet_v2_s.children())[2:3], nn.Dropout(0.1)),   # 48x25x25\n",
    "            nn.Sequential(*list(efficientnet_v2_s.children())[3:4], nn.Dropout(0.2)),   # 64x13x13\n",
    "            nn.Sequential(*list(efficientnet_v2_s.children())[4:5], nn.Dropout(0.2)),   # 128x7x7\n",
    "            nn.Sequential(*list(efficientnet_v2_s.children())[5:6], nn.Dropout(0.3)),   # 160x7x7\n",
    "            nn.Sequential(*list(efficientnet_v2_s.children())[6:7], nn.Dropout(0.3))    # 256x4x4\n",
    "        ])\n",
    "        \n",
    "        # Modularize upconvolutions\n",
    "        self.upconvs = nn.ModuleList([\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=160, kernel_size=2, stride=2, padding=1, output_padding=1),\n",
    "            nn.Conv2d(in_channels=160, out_channels=128, kernel_size=1, stride=1),\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=2, padding=1, output_padding=1),\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=48, kernel_size=2, stride=2, padding=1, output_padding=1),\n",
    "            nn.ConvTranspose2d(in_channels=48, out_channels=24, kernel_size=2, stride=2)\n",
    "        ])\n",
    "        \n",
    "        # Modularize decoders\n",
    "        self.decoders = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(160*2, 160, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                nn.SiLU(inplace=True),\n",
    "                nn.Dropout(0.3, inplace=True)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(128*2, 128, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                nn.SiLU(inplace=True),\n",
    "                nn.Dropout(0.3, inplace=True)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(64*2, 64, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                nn.SiLU(inplace=True),\n",
    "                nn.Dropout(0.2, inplace=True)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(48*2, 48, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                nn.SiLU(inplace=True),\n",
    "                nn.Dropout(0.2, inplace=True)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(24*2, 24, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                nn.SiLU(inplace=True),\n",
    "                nn.Dropout(0.1, inplace=True)\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        # Optional, merge layers to increase the number of channels\n",
    "        self.merge_layers = nn.Sequential(\n",
    "            nn.Conv2d(24, output_channel_size, kernel_size=1),\n",
    "            nn.BatchNorm2d(output_channel_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(output_feature_size) # to reduce noise and overfitting\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        features = []\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "            features.append(x)\n",
    "        \n",
    "        # Decoder\n",
    "        x = features.pop()\n",
    "        for upconv, decoder, feature in zip(self.upconvs, self.decoders, reversed(features)):\n",
    "            x = upconv(x)\n",
    "            x = torch.cat((x, feature), dim=1)\n",
    "            x = decoder(x)\n",
    "        \n",
    "        x = self.merge_layers(x) # Introduced to increase the number of channels\n",
    "        pooled_features = self.global_avg_pool(x) # Introduced to reduce noise and overfitting\n",
    "        \n",
    "        return pooled_features\n",
    "\n",
    "model = efficientDecoder_v2_s()\n",
    "\n",
    "# Print total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total number of parameters: \", total_params)\n",
    "\n",
    "# Example initialization and forward pass\n",
    "# model = EfficientDecoder_v2_s()\n",
    "dummy_input = torch.randn(10, 3, 100, 100)  # Adjust size according to your actual input\n",
    "output = model(dummy_input)\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 12 12\n"
     ]
    }
   ],
   "source": [
    "input_dim=(128,12,12)\n",
    "\n",
    "input_channels, input_height, input_width = input_dim\n",
    "\n",
    "print(input_channels, input_height, input_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters:  45460865\n",
      "torch.Size([50, 3, 100, 100])\n",
      "torch.Size([50, 256, 12, 12])\n",
      "Features shape: torch.Size([50, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.models.baseline_models import construct_baselineModel, construct_baseModel, BaseModel\n",
    "from src.models.backbone_models import densetFPN_121, densetFPN_201\n",
    "\n",
    "# model = densetFPN_121()\n",
    "# Create the model instance\n",
    "# model = BaseModel(backbone=densetFPN_121, weights='DEFAULT', input_dim=(256,12,12))\n",
    "model = construct_baseModel(backbone_name='densetFPN_121', weights='DEFAULT', input_dim=(256,12,12))\n",
    "\n",
    "# Print total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total number of parameters: \", total_params)\n",
    "\n",
    "# Create a dummy input tensor of size [50, 3, 100, 100]\n",
    "dummy_input = torch.randn(50, 3, 100, 100)\n",
    "\n",
    "# Forward pass through the model with dummy input\n",
    "features = model(dummy_input)\n",
    "\n",
    "# Print output shapes to verify\n",
    "print(\"Features shape:\", features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5106],\n",
       "         [0.5035],\n",
       "         [0.5488],\n",
       "         [0.7421],\n",
       "         [0.5720],\n",
       "         [0.3836],\n",
       "         [0.5911],\n",
       "         [0.4598],\n",
       "         [0.5526],\n",
       "         [0.5835],\n",
       "         [0.4567],\n",
       "         [0.5489],\n",
       "         [0.5642],\n",
       "         [0.4666],\n",
       "         [0.4395],\n",
       "         [0.6266],\n",
       "         [0.4210],\n",
       "         [0.5086],\n",
       "         [0.5422],\n",
       "         [0.5515],\n",
       "         [0.5906],\n",
       "         [0.6073],\n",
       "         [0.4439],\n",
       "         [0.5127],\n",
       "         [0.3540],\n",
       "         [0.6443],\n",
       "         [0.3925],\n",
       "         [0.5958],\n",
       "         [0.4544],\n",
       "         [0.4678],\n",
       "         [0.4648],\n",
       "         [0.5237],\n",
       "         [0.6828],\n",
       "         [0.5871],\n",
       "         [0.5303],\n",
       "         [0.5280],\n",
       "         [0.5333],\n",
       "         [0.6036],\n",
       "         [0.6479],\n",
       "         [0.5992],\n",
       "         [0.5446],\n",
       "         [0.5203],\n",
       "         [0.4284],\n",
       "         [0.5404],\n",
       "         [0.3937],\n",
       "         [0.5419],\n",
       "         [0.5040],\n",
       "         [0.5163],\n",
       "         [0.6542],\n",
       "         [0.6807]], grad_fn=<SigmoidBackward0>),\n",
       " [tensor([[0.3055],\n",
       "          [0.5454],\n",
       "          [0.4466],\n",
       "          [0.6103],\n",
       "          [0.6001],\n",
       "          [0.3678],\n",
       "          [0.5986],\n",
       "          [0.6536],\n",
       "          [0.4881],\n",
       "          [0.5223],\n",
       "          [0.4796],\n",
       "          [0.5688],\n",
       "          [0.4172],\n",
       "          [0.5538],\n",
       "          [0.5178],\n",
       "          [0.4031],\n",
       "          [0.3373],\n",
       "          [0.4337],\n",
       "          [0.4974],\n",
       "          [0.5876],\n",
       "          [0.4776],\n",
       "          [0.4990],\n",
       "          [0.4690],\n",
       "          [0.3868],\n",
       "          [0.4190],\n",
       "          [0.4670],\n",
       "          [0.4491],\n",
       "          [0.4863],\n",
       "          [0.6486],\n",
       "          [0.5797],\n",
       "          [0.5871],\n",
       "          [0.4863],\n",
       "          [0.6591],\n",
       "          [0.6616],\n",
       "          [0.5327],\n",
       "          [0.5821],\n",
       "          [0.4675],\n",
       "          [0.4971],\n",
       "          [0.5587],\n",
       "          [0.5801],\n",
       "          [0.4372],\n",
       "          [0.4937],\n",
       "          [0.5283],\n",
       "          [0.6593],\n",
       "          [0.5816],\n",
       "          [0.4639],\n",
       "          [0.4616],\n",
       "          [0.4363],\n",
       "          [0.5333],\n",
       "          [0.4207]], grad_fn=<SigmoidBackward0>),\n",
       "  tensor([[0.5994],\n",
       "          [0.4221],\n",
       "          [0.5482],\n",
       "          [0.5027],\n",
       "          [0.6056],\n",
       "          [0.4320],\n",
       "          [0.6220],\n",
       "          [0.3703],\n",
       "          [0.5256],\n",
       "          [0.4440],\n",
       "          [0.4216],\n",
       "          [0.6132],\n",
       "          [0.3906],\n",
       "          [0.5134],\n",
       "          [0.4589],\n",
       "          [0.5386],\n",
       "          [0.6318],\n",
       "          [0.5214],\n",
       "          [0.4835],\n",
       "          [0.5464],\n",
       "          [0.5554],\n",
       "          [0.6127],\n",
       "          [0.6334],\n",
       "          [0.4757],\n",
       "          [0.4426],\n",
       "          [0.4318],\n",
       "          [0.4770],\n",
       "          [0.6538],\n",
       "          [0.5836],\n",
       "          [0.3359],\n",
       "          [0.4776],\n",
       "          [0.5106],\n",
       "          [0.6561],\n",
       "          [0.3689],\n",
       "          [0.6169],\n",
       "          [0.5105],\n",
       "          [0.3370],\n",
       "          [0.6534],\n",
       "          [0.5109],\n",
       "          [0.3918],\n",
       "          [0.3841],\n",
       "          [0.4583],\n",
       "          [0.2671],\n",
       "          [0.6128],\n",
       "          [0.4786],\n",
       "          [0.6102],\n",
       "          [0.6577],\n",
       "          [0.4353],\n",
       "          [0.4571],\n",
       "          [0.3366]], grad_fn=<SigmoidBackward0>),\n",
       "  tensor([[0.4460],\n",
       "          [0.6588],\n",
       "          [0.4393],\n",
       "          [0.6087],\n",
       "          [0.6458],\n",
       "          [0.4906],\n",
       "          [0.6662],\n",
       "          [0.5403],\n",
       "          [0.5312],\n",
       "          [0.4761],\n",
       "          [0.5849],\n",
       "          [0.5742],\n",
       "          [0.6435],\n",
       "          [0.6641],\n",
       "          [0.6647],\n",
       "          [0.4585],\n",
       "          [0.5417],\n",
       "          [0.5283],\n",
       "          [0.6605],\n",
       "          [0.4294],\n",
       "          [0.4900],\n",
       "          [0.6886],\n",
       "          [0.7165],\n",
       "          [0.6609],\n",
       "          [0.4934],\n",
       "          [0.7271],\n",
       "          [0.4234],\n",
       "          [0.6486],\n",
       "          [0.4096],\n",
       "          [0.4861],\n",
       "          [0.6816],\n",
       "          [0.5638],\n",
       "          [0.6127],\n",
       "          [0.4007],\n",
       "          [0.5800],\n",
       "          [0.6046],\n",
       "          [0.3825],\n",
       "          [0.5914],\n",
       "          [0.5249],\n",
       "          [0.4637],\n",
       "          [0.6184],\n",
       "          [0.5453],\n",
       "          [0.4658],\n",
       "          [0.4733],\n",
       "          [0.4857],\n",
       "          [0.5889],\n",
       "          [0.4864],\n",
       "          [0.6486],\n",
       "          [0.6052],\n",
       "          [0.5207]], grad_fn=<SigmoidBackward0>),\n",
       "  tensor([[0.5050],\n",
       "          [0.5009],\n",
       "          [0.6103],\n",
       "          [0.6707],\n",
       "          [0.5870],\n",
       "          [0.6340],\n",
       "          [0.5019],\n",
       "          [0.6034],\n",
       "          [0.3063],\n",
       "          [0.5752],\n",
       "          [0.5361],\n",
       "          [0.4430],\n",
       "          [0.4081],\n",
       "          [0.4042],\n",
       "          [0.5211],\n",
       "          [0.5625],\n",
       "          [0.4112],\n",
       "          [0.3749],\n",
       "          [0.4609],\n",
       "          [0.4330],\n",
       "          [0.6415],\n",
       "          [0.5229],\n",
       "          [0.5643],\n",
       "          [0.4434],\n",
       "          [0.5848],\n",
       "          [0.5218],\n",
       "          [0.5058],\n",
       "          [0.5605],\n",
       "          [0.5861],\n",
       "          [0.5307],\n",
       "          [0.5698],\n",
       "          [0.4603],\n",
       "          [0.6568],\n",
       "          [0.5211],\n",
       "          [0.4777],\n",
       "          [0.6919],\n",
       "          [0.4847],\n",
       "          [0.5981],\n",
       "          [0.6647],\n",
       "          [0.4543],\n",
       "          [0.4405],\n",
       "          [0.4667],\n",
       "          [0.5407],\n",
       "          [0.4605],\n",
       "          [0.4388],\n",
       "          [0.3555],\n",
       "          [0.5299],\n",
       "          [0.5340],\n",
       "          [0.4613],\n",
       "          [0.5632]], grad_fn=<SigmoidBackward0>),\n",
       "  tensor([[0.5538],\n",
       "          [0.3049],\n",
       "          [0.4049],\n",
       "          [0.4058],\n",
       "          [0.2526],\n",
       "          [0.4906],\n",
       "          [0.4019],\n",
       "          [0.4169],\n",
       "          [0.3502],\n",
       "          [0.4746],\n",
       "          [0.5110],\n",
       "          [0.3587],\n",
       "          [0.4831],\n",
       "          [0.4644],\n",
       "          [0.5718],\n",
       "          [0.4495],\n",
       "          [0.5867],\n",
       "          [0.4463],\n",
       "          [0.4000],\n",
       "          [0.5336],\n",
       "          [0.5037],\n",
       "          [0.3760],\n",
       "          [0.4330],\n",
       "          [0.4684],\n",
       "          [0.4350],\n",
       "          [0.3580],\n",
       "          [0.4308],\n",
       "          [0.4418],\n",
       "          [0.4140],\n",
       "          [0.4800],\n",
       "          [0.3868],\n",
       "          [0.5566],\n",
       "          [0.5478],\n",
       "          [0.5501],\n",
       "          [0.4517],\n",
       "          [0.5007],\n",
       "          [0.5056],\n",
       "          [0.3112],\n",
       "          [0.3303],\n",
       "          [0.5946],\n",
       "          [0.4102],\n",
       "          [0.6776],\n",
       "          [0.4990],\n",
       "          [0.4830],\n",
       "          [0.6159],\n",
       "          [0.6093],\n",
       "          [0.3436],\n",
       "          [0.6166],\n",
       "          [0.4197],\n",
       "          [0.5501]], grad_fn=<SigmoidBackward0>)])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dictionary outside the class\n",
    "MODEL_DICT = {\n",
    "    'densetFPN_121': densetFPN_121,\n",
    "    'densetFPN_201': densetFPN_201,\n",
    "    'efficientFPN_v2_s': efficientFPN_v2_s,\n",
    "    'efficientDecoder_v2_s': efficientDecoder_v2_s\n",
    "}\n",
    "\n",
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, backbone, num_tasks=5, feature_dim=(256, 25, 25)):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        self.backbone = backbone()  # Instantiate the backbone passed as a class\n",
    "        \n",
    "        feature_channels, feature_width, feature_height = feature_dim\n",
    "        \n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((feature_width, feature_height))\n",
    "        \n",
    "        self.task_specific_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(feature_channels * feature_width * feature_height, 1024),\n",
    "                nn.BatchNorm1d(1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2)\n",
    "            ) for _ in range(num_tasks)\n",
    "        ])\n",
    "        \n",
    "        self.task_specific_classifier = nn.ModuleList([\n",
    "            nn.Linear(1024, 1) for _ in range(num_tasks)\n",
    "        ])\n",
    "        \n",
    "        self.final_classifier = nn.Sequential(\n",
    "            nn.Linear(1024 * num_tasks, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(1024, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        intermediate_outputs = [layer(x) for layer in self.task_specific_layers]\n",
    "        concatenated_outputs = torch.cat(intermediate_outputs, dim=1)\n",
    "        \n",
    "        task_outputs = [torch.sigmoid(classifier(io)) for io, classifier in zip(intermediate_outputs, self.task_specific_classifier)]\n",
    "        \n",
    "        final_output = torch.sigmoid(self.final_classifier(concatenated_outputs))\n",
    "        \n",
    "        return final_output, task_outputs\n",
    "\n",
    "def construct_baselineModel(model_name, num_tasks=5, feature_dim=(256, 25, 25)):\n",
    "    if model_name not in MODEL_DICT:\n",
    "        raise ValueError(f\"Unsupported model name {model_name}\")\n",
    "    backbone = MODEL_DICT[model_name]\n",
    "    return BaselineModel(backbone, num_tasks, feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denseFPN_121(\n",
      "  (encoder): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (4): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (5): _Transition(\n",
      "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (6): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): _Transition(\n",
      "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer13): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer14): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer15): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer16): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer17): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer18): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer19): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer20): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer21): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer22): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer23): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer24): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): _Transition(\n",
      "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): _DenseBlock(\n",
      "        (denselayer1): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer13): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer14): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer15): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer16): _DenseLayer(\n",
      "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (adaptation_layers): ModuleDict(\n",
      "    (adapt1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (adapt2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (adapt3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (adapt4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (fpn): ModuleDict(\n",
      "    (fpn1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from src.models.backbone_models import denseFPN_121, denseFPN_201\n",
    "\n",
    "# Create the model instance\n",
    "model = models.efficientnet_v2_s(weights=None).features[:-1]\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters:  7643776\n",
      "Features shape: torch.Size([50, 256, 12, 12])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Print output shapes to verify\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatures shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, features\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput channels:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_output_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\jerem\\Desktop\\ICL-MSc\\Final_Year_Project\\FYP-interpretable-deep-learning\\2D-model\\src\\models\\backbone_models.py:148\u001b[0m, in \u001b[0;36mdenseFPN_121.get_output_channels\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_output_channels\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    147\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Returns the number of output channels from the final convolutional layer. \"\"\"\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m     final_conv_layer \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfpn\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmodules() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, nn\u001b[38;5;241m.\u001b[39mConv2d)][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommon_channel_size, final_conv_layer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], final_conv_layer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py:463\u001b[0m, in \u001b[0;36mModuleDict.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;129m@_copy_to_script_wrapper\u001b[39m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Module:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: -1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.models.backbone_models import denseFPN_121, denseFPN_201\n",
    "\n",
    "# Create the model instance\n",
    "model = denseFPN_121()\n",
    "\n",
    "# Print total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total number of parameters: \", total_params)\n",
    "\n",
    "# Create a dummy input tensor of size [50, 3, 100, 100]\n",
    "dummy_input = torch.randn(50, 3, 100, 100)\n",
    "\n",
    "# Forward pass through the model with dummy input\n",
    "features = model(dummy_input)\n",
    "\n",
    "# Print output shapes to verify\n",
    "print(\"Features shape:\", features.shape)\n",
    "\n",
    "print(\"Output channels:\", model.get_output_channels())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Testing PPNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters:  15688838\n",
      "Backbone output shape: torch.Size([50, 512, 1, 1])\n",
      "Prototype vectors: 50\n",
      "Unsqueeze Prototype 0 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 1 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 2 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 3 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 4 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 5 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 6 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 7 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 8 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 9 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 10 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 11 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 12 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 13 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 14 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 15 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 16 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 17 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 18 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 19 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 20 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 21 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 22 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 23 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 24 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 25 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 26 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 27 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 28 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 29 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 30 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 31 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 32 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 33 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 34 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 35 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 36 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 37 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 38 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 39 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 40 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 41 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 42 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 43 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 44 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 45 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 46 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 47 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 48 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Unsqueeze Prototype 49 shape: torch.Size([1, 512, 1, 1]), task index: 0\n",
      "Distances shape: torch.Size([50, 512, 1, 1])\n",
      "Processed shape: torch.Size([50, 1024])\n",
      "Concatenated outputs shape: torch.Size([50, 51200])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (50x51200 and 5120x1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 108\u001b[0m\n\u001b[0;32m    105\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Forward pass through the model with dummy input\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m final_logits, task_logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Print output shapes to verify\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal logits shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, final_logits\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 73\u001b[0m, in \u001b[0;36mHybridProtoPNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     70\u001b[0m task_outputs \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_specific_classifier[i](intermediate_outputs[i])) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_specific_layers))]\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Final malignancy or comprehensive prediction\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m final_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcatenated_outputs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_output, task_outputs\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (50x51200 and 5120x1024)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "from helpers import list_of_distances, make_one_hot\n",
    "\n",
    "def _train_or_test(model, dataloader, optimizer=None, class_specific=True, use_l1_mask=True,\n",
    "                   coefs=None, log=print):\n",
    "    '''\n",
    "    model: the multi-gpu model\n",
    "    dataloader:\n",
    "    optimizer: if None, will be test evaluation\n",
    "    '''\n",
    "    is_train = optimizer is not None\n",
    "    start = time.time()\n",
    "    n_examples = 0\n",
    "    n_correct = 0\n",
    "    n_batches = 0\n",
    "    total_cross_entropy = 0\n",
    "    total_cluster_cost = 0\n",
    "    # separation cost is meaningful only for class_specific\n",
    "    total_separation_cost = 0\n",
    "    total_avg_separation_cost = 0\n",
    "\n",
    "    for i, (image, label) in enumerate(dataloader):\n",
    "        input = image.cuda()\n",
    "        target = label.cuda()\n",
    "\n",
    "        # torch.enable_grad() has no effect outside of no_grad()\n",
    "        grad_req = torch.enable_grad() if is_train else torch.no_grad()\n",
    "        with grad_req:\n",
    "            # nn.Module has implemented __call__() function\n",
    "            # so no need to call .forward\n",
    "            output, min_distances = model(input)\n",
    "\n",
    "            # compute loss\n",
    "            cross_entropy = torch.nn.functional.cross_entropy(output, target)\n",
    "\n",
    "            if class_specific:\n",
    "                max_dist = (model.module.prototype_shape[1]\n",
    "                            * model.module.prototype_shape[2]\n",
    "                            * model.module.prototype_shape[3])\n",
    "\n",
    "                # prototypes_of_correct_class is a tensor of shape batch_size * num_prototypes\n",
    "                # calculate cluster cost\n",
    "                prototypes_of_correct_class = torch.t(model.module.prototype_class_identity[:,label]).cuda()\n",
    "                inverted_distances, _ = torch.max((max_dist - min_distances) * prototypes_of_correct_class, dim=1)\n",
    "                cluster_cost = torch.mean(max_dist - inverted_distances)\n",
    "\n",
    "                # calculate separation cost\n",
    "                prototypes_of_wrong_class = 1 - prototypes_of_correct_class\n",
    "                inverted_distances_to_nontarget_prototypes, _ = \\\n",
    "                    torch.max((max_dist - min_distances) * prototypes_of_wrong_class, dim=1)\n",
    "                separation_cost = torch.mean(max_dist - inverted_distances_to_nontarget_prototypes)\n",
    "\n",
    "                # calculate avg cluster cost\n",
    "                avg_separation_cost = \\\n",
    "                    torch.sum(min_distances * prototypes_of_wrong_class, dim=1) / torch.sum(prototypes_of_wrong_class, dim=1)\n",
    "                avg_separation_cost = torch.mean(avg_separation_cost)\n",
    "                \n",
    "                if use_l1_mask:\n",
    "                    l1_mask = 1 - torch.t(model.module.prototype_class_identity).cuda()\n",
    "                    l1 = (model.module.last_layer.weight * l1_mask).norm(p=1)\n",
    "                else:\n",
    "                    l1 = model.module.last_layer.weight.norm(p=1) \n",
    "\n",
    "            else:\n",
    "                min_distance, _ = torch.min(min_distances, dim=1)\n",
    "                cluster_cost = torch.mean(min_distance)\n",
    "                l1 = model.module.last_layer.weight.norm(p=1)\n",
    "\n",
    "            # evaluation statistics\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            n_examples += target.size(0)\n",
    "            n_correct += (predicted == target).sum().item()\n",
    "\n",
    "            n_batches += 1\n",
    "            total_cross_entropy += cross_entropy.item()\n",
    "            total_cluster_cost += cluster_cost.item()\n",
    "            total_separation_cost += separation_cost.item()\n",
    "            total_avg_separation_cost += avg_separation_cost.item()\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        if is_train:\n",
    "            if class_specific:\n",
    "                if coefs is not None:\n",
    "                    loss = (coefs['crs_ent'] * cross_entropy\n",
    "                          + coefs['clst'] * cluster_cost\n",
    "                          + coefs['sep'] * separation_cost\n",
    "                          + coefs['l1'] * l1)\n",
    "                else:\n",
    "                    loss = cross_entropy + 0.8 * cluster_cost - 0.08 * separation_cost + 1e-4 * l1\n",
    "            else:\n",
    "                if coefs is not None:\n",
    "                    loss = (coefs['crs_ent'] * cross_entropy\n",
    "                          + coefs['clst'] * cluster_cost\n",
    "                          + coefs['l1'] * l1)\n",
    "                else:\n",
    "                    loss = cross_entropy + 0.8 * cluster_cost + 1e-4 * l1\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        del input\n",
    "        del target\n",
    "        del output\n",
    "        del predicted\n",
    "        del min_distances\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    log('\\ttime: \\t{0}'.format(end -  start))\n",
    "    log('\\tcross ent: \\t{0}'.format(total_cross_entropy / n_batches))\n",
    "    log('\\tcluster: \\t{0}'.format(total_cluster_cost / n_batches))\n",
    "    if class_specific:\n",
    "        log('\\tseparation:\\t{0}'.format(total_separation_cost / n_batches))\n",
    "        log('\\tavg separation:\\t{0}'.format(total_avg_separation_cost / n_batches))\n",
    "    log('\\taccu: \\t\\t{0}%'.format(n_correct / n_examples * 100))\n",
    "    log('\\tl1: \\t\\t{0}'.format(model.module.last_layer.weight.norm(p=1).item()))\n",
    "    p = model.module.prototype_vectors.view(model.module.num_prototypes, -1).cpu()\n",
    "    with torch.no_grad():\n",
    "        p_avg_pair_dist = torch.mean(list_of_distances(p, p))\n",
    "    log('\\tp dist pair: \\t{0}'.format(p_avg_pair_dist.item()))\n",
    "\n",
    "    return n_correct / n_examples\n",
    "\n",
    "\n",
    "def train(model, dataloader, optimizer, class_specific=False, coefs=None, log=print):\n",
    "    assert(optimizer is not None)\n",
    "    \n",
    "    log('\\ttrain')\n",
    "    model.train()\n",
    "    return _train_or_test(model=model, dataloader=dataloader, optimizer=optimizer,\n",
    "                          class_specific=class_specific, coefs=coefs, log=log)\n",
    "\n",
    "\n",
    "def test(model, dataloader, class_specific=False, log=print):\n",
    "    log('\\ttest')\n",
    "    model.eval()\n",
    "    return _train_or_test(model=model, dataloader=dataloader, optimizer=None,\n",
    "                          class_specific=class_specific, log=log)\n",
    "\n",
    "\n",
    "def last_only(model, log=print):\n",
    "    for p in model.module.features.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.module.add_on_layers.parameters():\n",
    "        p.requires_grad = False\n",
    "    model.module.prototype_vectors.requires_grad = False\n",
    "    for p in model.module.last_layer.parameters():\n",
    "        p.requires_grad = True\n",
    "    \n",
    "    log('\\tlast layer')\n",
    "\n",
    "\n",
    "def warm_only(model, log=print):\n",
    "    for p in model.module.features.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.module.add_on_layers.parameters():\n",
    "        p.requires_grad = True\n",
    "    model.module.prototype_vectors.requires_grad = True\n",
    "    for p in model.module.last_layer.parameters():\n",
    "        p.requires_grad = True\n",
    "    \n",
    "    log('\\twarm')\n",
    "\n",
    "\n",
    "def joint(model, log=print):\n",
    "    for p in model.module.features.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in model.module.add_on_layers.parameters():\n",
    "        p.requires_grad = True\n",
    "    model.module.prototype_vectors.requires_grad = True\n",
    "    for p in model.module.last_layer.parameters():\n",
    "        p.requires_grad = True\n",
    "    \n",
    "    log('\\tjoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import optimizer\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def _train_or_test(model, data_loader, optimizer, device, is_train=True, use_l1_mask=True, coefs=None, task_weights=None):\n",
    "    model.to(device)\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    total_correct = [0] * 5  # For tasks\n",
    "    total_samples = [0] * 5  # For tasks\n",
    "    \n",
    "    task_cross_entropy = [0.0] * 5\n",
    "    task_cluster_cost = [0.0] * 5\n",
    "    task_separation_cost = [0.0] * 5\n",
    "    task_avg_separation_cost = [0.0] * 5\n",
    "    task_l1 = [0.0] * 5\n",
    "    final_pred_targets = [[] for _ in range(5)]\n",
    "    final_pred_outputs = [[] for _ in range(5)]\n",
    "    \n",
    "    final_correct = 0  # For final output\n",
    "    final_samples = 0  # For final output\n",
    "    final_targets = []  # For calculating balanced accuracy for final output\n",
    "    final_outputs = []  # For calculating balanced accuracy for final output\n",
    "    \n",
    "    n_batches = 0\n",
    "    context = torch.enable_grad() if is_train else torch.no_grad()\n",
    "    with context:\n",
    "        for X, targets, bweights_chars, final_target, bweight in tqdm(data_loader, leave=False):\n",
    "            X = X.to(device)\n",
    "            bweights_chars = [b.float().to(device) for b in bweights_chars]\n",
    "            \n",
    "            targets2 = [F.one_hot(t.squeeze(), num_classes=2).float().to(device) for t in targets]\n",
    "            targets = [t.squeeze().to(device) for t in targets]\n",
    "            final_target = final_target.float().unsqueeze(1).to(device)\n",
    "            bweight = bweight.float().unsqueeze(1).to(device)\n",
    "            \n",
    "            final_output, task_outputs, min_distances = model(X)\n",
    "            \n",
    "            batch_loss = 0.0\n",
    "            for i, (task_output, min_distance, target, bweight_char) in enumerate(zip(task_outputs, min_distances, targets, bweights_chars)):\n",
    "                # Get the prototype identity for each characteristic\n",
    "                prototype_char_identity = model.prototype_class_identity[i].to(device)\n",
    "                \n",
    "                # Get the max distance between prototypes\n",
    "                max_dist = (model.prototype_shape[1] * model.prototype_shape[2] * model.prototype_shape[3])\n",
    "                \n",
    "                # Compute cross entropy cost for each characteristic\n",
    "                cross_entropy = torch.nn.functional.cross_entropy(task_output, target, weight=bweight_char[0])\n",
    "\n",
    "                # Compute cluster cost for each characteristic\n",
    "                prototypes_of_correct_class = torch.t(prototype_char_identity[:,target]).to(device)    # batch_size * num_prototypes\n",
    "                inverted_distances, _ = torch.max((max_dist - min_distance) * prototypes_of_correct_class, dim=1)\n",
    "                cluster_cost = torch.mean(max_dist - inverted_distances) # Increase the distance between the prototypes of the same class\n",
    "\n",
    "                # Compute separation cost for each characteristic\n",
    "                prototypes_of_wrong_class = 1 - prototypes_of_correct_class\n",
    "                inverted_distances_to_nontarget_prototypes, _ = torch.max((max_dist - min_distance) * prototypes_of_wrong_class, dim=1)\n",
    "                separation_cost = torch.mean(max_dist - inverted_distances_to_nontarget_prototypes) # Decrease the distance between the prototypes of different classes\n",
    "\n",
    "                # Compute average separation cost for each characteristic\n",
    "                avg_separation_cost = torch.sum(min_distance * prototypes_of_wrong_class, dim=1) / torch.sum(prototypes_of_wrong_class, dim=1)\n",
    "                avg_separation_cost = torch.mean(avg_separation_cost)\n",
    "                \n",
    "                # Compute l1 regularization for each characteristic\n",
    "                if use_l1_mask:\n",
    "                    l1_mask = 1 - torch.t(prototype_char_identity).to(device)\n",
    "                    l1 = (model.task_specific_classifier[i].weight * l1_mask).norm(p=1)\n",
    "                else:\n",
    "                    l1 = model.task_specific_classifier[i].weight.norm(p=1) \n",
    "                    \n",
    "                # Compute accuracy for each characteristic\n",
    "                preds = task_output.argmax(dim=1)\n",
    "                total_correct[i] += (preds == target).sum().item()\n",
    "                total_samples[i] += target.size(0)\n",
    "                \n",
    "                # Collect data for balanced accuracy for each characteristic\n",
    "                final_pred_targets[i].extend(target.cpu().numpy())\n",
    "                final_pred_outputs[i].extend(preds.detach().cpu().numpy())\n",
    "\n",
    "                task_cross_entropy[i] += cross_entropy.item()\n",
    "                task_cluster_cost[i] += cluster_cost.item()\n",
    "                task_separation_cost[i] += separation_cost.item()\n",
    "                task_avg_separation_cost[i] += avg_separation_cost.item()\n",
    "                task_l1[i] += l1\n",
    "                \n",
    "                batch_loss += (coefs['crs_ent'] * cross_entropy + \n",
    "                               coefs['clst'] * cluster_cost + \n",
    "                               coefs['sep'] * separation_cost +\n",
    "                               coefs['l1'] * l1)\n",
    "\n",
    "            # Compute binary cross entropy loss for final output\n",
    "            final_loss = torch.nn.functional.binary_cross_entropy(final_output, final_target, weight=bweight)\n",
    "            batch_loss += final_loss\n",
    "            \n",
    "            # Compute statistics for final accuracy\n",
    "            final_preds = final_output.round()\n",
    "            final_correct += (final_preds == final_target).sum().item()\n",
    "            final_samples += final_target.size(0)\n",
    "            final_targets.extend(final_target.cpu().numpy())\n",
    "            final_outputs.extend(final_preds.detach().cpu().numpy())\n",
    "            \n",
    "            total_loss += batch_loss.item()  # Sum up total loss\n",
    "            \n",
    "            # compute gradient and do SGD step\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            n_batches += 1\n",
    "    \n",
    "    # TODO: Add the seperate characteristic losses to the return dictionary, and include final F1 score, final precision, final recall, and final AUC\n",
    "    average_loss = total_loss / n_batches\n",
    "    task_accuracies = [correct / samples for correct, samples in zip(total_correct, total_samples)]\n",
    "    task_balanced_accuracies = [balanced_accuracy_score(targets, outputs) for targets, outputs in zip(final_pred_targets, final_pred_outputs)]\n",
    "    final_accuracy = final_correct / final_samples\n",
    "    final_balanced_accuracy = balanced_accuracy_score(final_targets, final_outputs)\n",
    "    # final_f1 = f1_score(final_targets, final_outputs)\n",
    "    # final_precision = precision_score(final_targets, final_outputs)\n",
    "    # final_recall = recall_score(final_targets, final_outputs)\n",
    "    # final_auc = roc_auc_score(final_targets, final_outputs)\n",
    "    \n",
    "    # task_cross_entropy = [t / n_batches for t in task_cross_entropy]\n",
    "    # task_cluster_cost = [t / n_batches for t in task_cluster_cost]\n",
    "    # task_separation_cost = [t / n_batches for t in task_separation_cost]\n",
    "    # task_avg_separation_cost = [t / n_batches for t in task_avg_separation_cost]\n",
    "    # task_l1 = [t / n_batches for t in task_l1]\n",
    "    \n",
    "    # return the metrics as a dictionary\n",
    "    metrics = {'average_loss': average_loss, \n",
    "               'task_accuracies': task_accuracies, \n",
    "               'task_balanced_accuracies': task_balanced_accuracies, \n",
    "               'final_accuracy': final_accuracy, \n",
    "               'final_balanced_accuracy': final_balanced_accuracy}\n",
    "               # 'task_cross_entropy': task_cross_entropy,\n",
    "               # 'task_cluster_cost': task_cluster_cost,\n",
    "               # 'task_separation_cost': task_separation_cost,\n",
    "               # 'task_avg_separation_cost': task_avg_separation_cost,\n",
    "               # 'task_l1': task_l1}\n",
    "    \n",
    "    if is_train:\n",
    "        return metrics\n",
    "    else:\n",
    "        return metrics\n",
    "\n",
    "def train_ppnet(model, data_loader, optimizer, device, use_l1_mask=True, coefs=None, task_weights=None):\n",
    "    train_metrics = _train_or_test(model, data_loader, optimizer, device, is_train=True, use_l1_mask=use_l1_mask, coefs=coefs, task_weights=task_weights)\n",
    "    print(f\"Train loss: {train_metrics['average_loss']:.5f}\")\n",
    "    for i, (acc, bal_acc) in enumerate(zip(train_metrics['task_accuracies'], train_metrics['task_balanced_accuracies']), 1):\n",
    "        print(f\"Task {i} - Train Accuracy: {acc*100:.2f}%, Train Balanced Accuracy: {bal_acc*100:.2f}%\")\n",
    "    # Print the metrics for the final output\n",
    "    print(f\"Final Output - Train Accuracy: {train_metrics['final_accuracy']*100:.2f}%, Train Balanced Accuracy: {train_metrics['final_balanced_accuracy']*100:.2f}%\")\n",
    "    return train_metrics\n",
    "\n",
    "def test_ppnet(model, data_loader, device, use_l1_mask=True, coefs=None, task_weights=None):\n",
    "    test_metrics = _train_or_test(model, data_loader, None, device, is_train=False, use_l1_mask=use_l1_mask, coefs=coefs, task_weights=task_weights)\n",
    "    print(f\"Test loss: {test_metrics['average_loss']:.5f}\")\n",
    "    for i, (acc, bal_acc) in enumerate(zip(test_metrics['task_accuracies'], test_metrics['task_balanced_accuracies']), 1):\n",
    "        print(f\"Task {i} - Test Accuracy: {acc*100:.2f}%, Test Balanced Accuracy: {bal_acc*100:.2f}%\")\n",
    "    # Print the metrics for the final output\n",
    "    print(f\"Final Output - Test Accuracy: {test_metrics['final_accuracy']*100:.2f}%, Test Balanced Accuracy: {test_metrics['final_balanced_accuracy']*100:.2f}%\")\n",
    "    return test_metrics\n",
    "            \n",
    "def last_only(model):\n",
    "    for p in model.features.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.add_on_layers.parameters():\n",
    "        p.requires_grad = False\n",
    "    model.prototype_vectors.requires_grad = False\n",
    "    for p in model.task_specific_classifier.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in model.final_classifier.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "def warm_only(model):\n",
    "    for p in model.features.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.add_on_layers.parameters():\n",
    "        p.requires_grad = True\n",
    "    model.prototype_vectors.requires_grad = False\n",
    "    for p in model.task_specific_classifier.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in model.final_classifier.parameters():\n",
    "        p.requires_grad = True\n",
    "        \n",
    "def joint(model):\n",
    "    for p in model.features.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in model.add_on_layers.parameters():\n",
    "        p.requires_grad = True\n",
    "    model.prototype_vectors.requires_grad = False\n",
    "    for p in model.task_specific_classifier.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in model.final_classifier.parameters():\n",
    "        p.requires_grad = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters:  7778845\n",
      "torch.Size([10, 20])\n",
      "torch.Size([10, 20])\n",
      "torch.Size([10, 20])\n",
      "torch.Size([10, 20])\n",
      "torch.Size([10, 20])\n",
      "torch.Size([10, 100])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10x100 and 10x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 272\u001b[0m\n\u001b[0;32m    269\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# Forward pass through the model with dummy input\u001b[39;00m\n\u001b[1;32m--> 272\u001b[0m final_output, task_logits, min_distances \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;66;03m# Print output shapes to verify\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_logits shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, [task_logit\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m task_logit \u001b[38;5;129;01min\u001b[39;00m task_logits])  \n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 207\u001b[0m, in \u001b[0;36mPPNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m# Concatenate task distances for the final classifier\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;66;03m# final_output = torch.sigmoid(self.final_classifier(torch.cat(distances, dim=1))) # TODO: Use intermediate task logits instead of distances and feature extractor output\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcat(similarities, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 207\u001b[0m final_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimilarities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_output, task_logits, min_distances\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x100 and 10x1)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "from src.utils.receptive_field import compute_proto_layer_rf_info_v2\n",
    "from src.models.backbone_models import denseFPN_121, denseFPN_201, efficientFPN_v2_s, efficientDecoder_v2_s, denseNet121, denseNet201\n",
    "\n",
    "# Dictionary of supported backbone models\n",
    "BACKBONE_DICT = {\n",
    "    'denseNet121': denseNet121,\n",
    "    'denseNet201': denseNet201,\n",
    "    'efficientNetV2_s': models.efficientnet_v2_s(weights='DEFAULT').features[:-1],\n",
    "    'denseFPN_121': denseFPN_121,\n",
    "    'denseFPN_201': denseFPN_201,\n",
    "    'efficientFPN_v2_s': efficientFPN_v2_s,\n",
    "    'efficientDecoder_v2_s': efficientDecoder_v2_s\n",
    "}\n",
    "\n",
    "class PPNet(nn.Module):\n",
    "    def __init__(self, features, img_size, prototype_shape, num_characteristics, proto_layer_rf_info=None, init_weights=True, prototype_activation_function='log', add_on_layers_type='bottleneck'):\n",
    "        super(PPNet, self).__init__()\n",
    "        # Define the input configurations\n",
    "        self.img_size = img_size # size of the input images (e.g. (3, 224, 224))\n",
    "        self.prototype_shape = prototype_shape # shape of the prototype vectors (e.g. (2000, 512, 1, 1))\n",
    "        self.num_characteristics = num_characteristics # number of characteristics to predict (e.g. shape, margin, etc.)\n",
    "        self.num_classes = 2 # binary classification\n",
    "        \n",
    "        self.num_prototypes = self.prototype_shape[0] # total number of prototypes\n",
    "        self.prototypes_per_characteristic = self.num_prototypes // self.num_characteristics # number of prototypes per characteristic\n",
    "        self.prototypes_per_class = self.prototypes_per_characteristic // self.num_classes # number of prototypes per class\n",
    "        \n",
    "        self.proto_layer_rf_info = proto_layer_rf_info\n",
    "        self.epsilon = 1e-4 # small value to avoid numerical instability\n",
    "\n",
    "        self.prototype_activation_function = prototype_activation_function # activation function for the prototypes\n",
    "        \n",
    "        self.prototype_class_identity = self._get_prototype_class_identity() # class identity of the prototypes\n",
    "        \n",
    "        # Define the feature extractor\n",
    "        self.features = features\n",
    "        \n",
    "        # Define the add-on layers\n",
    "        first_add_on_layer_in_channels = features.get_output_channels()\n",
    "        # self.add_on_layers = self.initialize_add_on_layers(first_add_on_layer_in_channels, add_on_layers_type)\n",
    "        if add_on_layers_type == 'bottleneck':\n",
    "            add_on_layers = []\n",
    "            current_in_channels = first_add_on_layer_in_channels\n",
    "            while (current_in_channels > self.prototype_shape[1]) or (len(add_on_layers) == 0):\n",
    "                current_out_channels = max(self.prototype_shape[1], (current_in_channels // 2))\n",
    "                add_on_layers.append(nn.Conv2d(in_channels=current_in_channels,\n",
    "                                               out_channels=current_out_channels,\n",
    "                                               kernel_size=1))\n",
    "                add_on_layers.append(nn.ReLU())\n",
    "                add_on_layers.append(nn.Conv2d(in_channels=current_out_channels,\n",
    "                                               out_channels=current_out_channels,\n",
    "                                               kernel_size=1))\n",
    "                if current_out_channels > self.prototype_shape[1]:\n",
    "                    add_on_layers.append(nn.ReLU())\n",
    "                else:\n",
    "                    assert(current_out_channels == self.prototype_shape[1])\n",
    "                    add_on_layers.append(nn.Sigmoid())\n",
    "                current_in_channels = current_in_channels // 2\n",
    "            self.add_on_layers = nn.Sequential(*add_on_layers)\n",
    "        else:\n",
    "            self.add_on_layers = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=first_add_on_layer_in_channels, out_channels=self.prototype_shape[1], kernel_size=1),\n",
    "                nn.BatchNorm2d(self.prototype_shape[1]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Conv2d(in_channels=self.prototype_shape[1], out_channels=self.prototype_shape[1], kernel_size=1),\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "        \n",
    "        # Define separate prototype vectors for each characteristic\n",
    "        self.prototype_vectors = nn.ParameterList([\n",
    "            nn.Parameter(torch.rand(self.prototypes_per_characteristic, prototype_shape[1], prototype_shape[2], prototype_shape[3]), requires_grad=True) for _ in range(self.num_characteristics)\n",
    "        ])\n",
    "        \n",
    "        # Define a tensor of ones for the l2-convolution\n",
    "        self.ones = nn.Parameter(torch.ones(self.prototypes_per_characteristic, prototype_shape[1], prototype_shape[2], prototype_shape[3]), requires_grad=False)\n",
    "\n",
    "        # Define a separate classifier for each characteristic\n",
    "        self.task_specific_classifier = nn.ModuleList([\n",
    "            nn.Linear(self.prototypes_per_characteristic, self.num_classes) for _ in range(self.num_characteristics)   # Apply softmax to get confidence scores for each class of each characteristic\n",
    "        ])\n",
    "        \n",
    "        self.final_classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # nn.Linear(self.num_characteristics*self.prototypes_per_characteristic*12*12, self.num_characteristics*self.num_classes), # HxW is the output size of the feature extractor\n",
    "            # nn.BatchNorm1d(self.num_characteristics*self.num_classes),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.2),\n",
    "            nn.Linear(self.num_characteristics*self.prototypes_per_characteristic, 1)\n",
    "        )\n",
    "\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "            self._set_last_layer_incorrect_connection(-0.5)\n",
    "    \n",
    "    def _get_prototype_class_identity(self):\n",
    "        \"\"\"\n",
    "        Initialize the class identities of the prototypes structured by characteristics.\n",
    "        Each characteristic has a tensor of size [num_prototypes_per_characteristic, num_classes].\n",
    "        \"\"\"\n",
    "        prototype_class_identity = []\n",
    "        num_prototypes_per_class = self.prototypes_per_characteristic // self.num_classes\n",
    "        \n",
    "        # Create a separate class identity matrix for each characteristic\n",
    "        for _ in range(self.num_characteristics):\n",
    "            # Initialize a zero matrix for current characteristic\n",
    "            class_identity = torch.zeros(self.prototypes_per_characteristic, self.num_classes)\n",
    "            \n",
    "            # Assign prototypes to each class (binary: two classes per characteristic)\n",
    "            for j in range(self.prototypes_per_characteristic):\n",
    "                class_index = j // num_prototypes_per_class\n",
    "                class_identity[j, class_index] = 1\n",
    "            \n",
    "            prototype_class_identity.append(class_identity)\n",
    "        \n",
    "        return prototype_class_identity\n",
    "    \n",
    "    def _set_last_layer_incorrect_connection(self, incorrect_strength):\n",
    "        '''\n",
    "        the incorrect strength will be actual strength if -0.5 then input -0.5\n",
    "        '''\n",
    "        for i in range(self.num_characteristics):\n",
    "            positive_one_weights_locations = torch.t(self.prototype_class_identity[i])\n",
    "            negative_one_weights_locations = 1 - positive_one_weights_locations\n",
    "            \n",
    "            correct_class_connection = 1\n",
    "            incorrect_class_connection = incorrect_strength\n",
    "            self.task_specific_classifier[i].weight.data.copy_(\n",
    "                correct_class_connection * positive_one_weights_locations\n",
    "                + incorrect_class_connection * negative_one_weights_locations)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.add_on_layers.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # every init technique has an underscore _ in the name\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def _l2_convolution(self, x, prototype_vector):\n",
    "        '''\n",
    "        apply prototype_vector as l2-convolution filters on input x\n",
    "        '''\n",
    "        x2 = x ** 2\n",
    "        x2_patch_sum = F.conv2d(input=x2, weight=self.ones)\n",
    "\n",
    "        p2 = prototype_vector ** 2\n",
    "        p2 = torch.sum(p2, dim=(1, 2, 3))\n",
    "        # p2 is a vector of shape (num_prototypes_per_characteristic,)\n",
    "        # then we reshape it to (num_prototypes_per_characteristic, 1, 1)\n",
    "        p2_reshape = p2.view(-1, 1, 1)\n",
    "\n",
    "        xp = F.conv2d(input=x, weight=prototype_vector)\n",
    "        intermediate_result = - 2 * xp + p2_reshape  # use broadcast\n",
    "        # x2_patch_sum and intermediate_result are of the same shape\n",
    "        distances = F.relu(x2_patch_sum + intermediate_result)\n",
    "\n",
    "        return distances\n",
    "\n",
    "    def distance_2_similarity(self, distances):\n",
    "        if self.prototype_activation_function == 'log':\n",
    "            return torch.log((distances + 1) / (distances + self.epsilon))\n",
    "        elif self.prototype_activation_function == 'linear':\n",
    "            return -distances\n",
    "        else:\n",
    "            return self.prototype_activation_function(distances)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Extract features using the backbone\n",
    "        x = self.features(x) # B x 256 x H x W\n",
    "        \n",
    "        # Apply add-on layers to the features\n",
    "        x = self.add_on_layers(x) # B x 512 x H x W\n",
    "        \n",
    "        # Compute distances and task logits for each characteristic\n",
    "        task_logits = []\n",
    "        task_probabilities = []\n",
    "        similarities = []\n",
    "        min_distances = []\n",
    "        for i in range(self.num_characteristics):\n",
    "            distance = self._l2_convolution(x, self.prototype_vectors[i]) # B x num_prototypes_per_characteristic x H x W, B x num_prototypes_per_characteristic x 1 x 1\n",
    "            min_distance = -F.max_pool2d(-distance, kernel_size=(distance.size()[2], distance.size()[3])) # B x num_prototypes_per_characteristic x 1 x 1\n",
    "            min_distance = min_distance.view(-1, self.prototypes_per_characteristic) # B x num_prototypes_per_characteristic\n",
    "            similarity = self.distance_2_similarity(min_distance) # B x num_prototypes_per_characteristic\n",
    "            task_logit = self.task_specific_classifier[i](similarity) # B x 2\n",
    "            task_probability = F.softmax(task_logit, dim=1)\n",
    "                        \n",
    "            similarities.append(similarity)\n",
    "            min_distances.append(min_distance)\n",
    "            task_logits.append(task_logit)\n",
    "            task_probabilities.append(task_probability)\n",
    "        \n",
    "        # Concatenate task distances for the final classifier\n",
    "        # final_output = torch.sigmoid(self.final_classifier(torch.cat(distances, dim=1))) # TODO: Use intermediate task logits instead of distances and feature extractor output\n",
    "        print(torch.cat(similarities, dim=1).shape)\n",
    "        final_output = torch.sigmoid(self.final_classifier(torch.cat(similarities, dim=1)))\n",
    "        return final_output, task_logits, min_distances\n",
    "                    \n",
    "    def push_forward(self, x):\n",
    "        '''this method is needed for the pushing operation'''\n",
    "        x = self.features(x)\n",
    "        x = self.add_on_layers(x)\n",
    "        distances = []\n",
    "        for i in range(self.num_characteristics):\n",
    "            distance = self._l2_convolution(x, self.prototype_vectors[i])\n",
    "            distances.append(distance)\n",
    "        return x, distances\n",
    "    \n",
    "    \n",
    "    # TODO: Implement the pruning operation\n",
    "\n",
    "\n",
    "def construct_PPNet(\n",
    "    base_architecture='denseNet121', \n",
    "    weights='DEFAULT', \n",
    "    img_size=224,\n",
    "    prototype_shape=(50*5*2, 224, 1, 1), \n",
    "    num_characteristics=5,\n",
    "    prototype_activation_function='log',\n",
    "    add_on_layers_type='bottleneck'\n",
    "):\n",
    "    \n",
    "    features = BACKBONE_DICT[base_architecture](weights=weights)\n",
    "    \n",
    "    layer_filter_sizes, layer_strides, layer_paddings = features.conv_info()\n",
    "    \n",
    "    proto_layer_rf_info = compute_proto_layer_rf_info_v2(\n",
    "        img_size=img_size,  \n",
    "        layer_filter_sizes=layer_filter_sizes,\n",
    "        layer_strides=layer_strides,\n",
    "        layer_paddings=layer_paddings,\n",
    "        prototype_kernel_size=prototype_shape[2]\n",
    "    )\n",
    "    \n",
    "    return PPNet(\n",
    "        features=features,\n",
    "        img_size=img_size,\n",
    "        prototype_shape=prototype_shape,\n",
    "        num_characteristics=num_characteristics,\n",
    "        proto_layer_rf_info=proto_layer_rf_info,\n",
    "        init_weights=True,\n",
    "        prototype_activation_function=prototype_activation_function,\n",
    "        add_on_layers_type=add_on_layers_type\n",
    "    )\n",
    "    \n",
    "# Set torch seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# model = PPNet(features=denseFPN_121(), img_size=(3, 100, 100), prototype_shape=(10*5*2, 224, 1, 1), num_characteristics=5, init_weights=True, prototype_activation_function='log', add_on_layers_type='bottleneck')\n",
    "\n",
    "model = construct_PPNet(base_architecture='denseFPN_121', weights='DEFAULT', img_size=100, prototype_shape=(10*5*2, 224, 1, 1), num_characteristics=5, prototype_activation_function='log', add_on_layers_type='bottleneck')\n",
    "\n",
    "# Print total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total number of parameters: \", total_params)\n",
    "\n",
    "# Create a dummy input tensor of size [50, 3, 100, 100]\n",
    "dummy_input = torch.randn(10, 3, 100, 100)\n",
    "\n",
    "# Forward pass through the model with dummy input\n",
    "final_output, task_logits, min_distances = model(dummy_input)\n",
    "\n",
    "# Print output shapes to verify\n",
    "print(\"task_logits shape:\", [task_logit.shape for task_logit in task_logits])  \n",
    "print(\"final_output shape:\", final_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from src.loaders.dataloader import LIDCDataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "\n",
    "IMG_CHANNELS = 3\n",
    "IMG_SIZE = 100\n",
    "CHOSEN_CHARS = [False, True, False, True, True, False, False, True, True]\n",
    "labels_file = './dataset/Meta/meta_info_old.csv'\n",
    "\n",
    "mean = (0.5, 0.5, 0.5)\n",
    "std = (0.5, 0.5, 0.5)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3), \n",
    "    transforms.Resize(256),  # First resize to larger dimensions\n",
    "    transforms.CenterCrop(224),  # Then crop to 224x224\n",
    "    transforms.ToTensor(),  # Convert to tensor (also scales pixel values to [0, 1])\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "# train set\n",
    "LIDC_trainset = LIDCDataset(labels_file=labels_file, chosen_chars=CHOSEN_CHARS, auto_split=True, zero_indexed=False, \n",
    "                                                        transform=transforms.Compose([transforms.Grayscale(num_output_channels=IMG_CHANNELS), \n",
    "                                                                    transforms.Resize(size=(IMG_SIZE, IMG_SIZE), interpolation=Image.BILINEAR), \n",
    "                                                                    transforms.ToTensor(), \n",
    "                                                                    # transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "                                                                    transforms.Normalize(mean, std)\n",
    "                                                                    ]),\n",
    "                                                        train=True)\n",
    "train_dataloader = torch.utils.data.DataLoader(LIDC_trainset, batch_size=50, shuffle=True, num_workers=4)\n",
    "# test set\n",
    "LIDC_testset = LIDCDataset(labels_file=labels_file, chosen_chars=CHOSEN_CHARS, auto_split=True, zero_indexed=False, \n",
    "                                                        transform=transforms.Compose([transforms.Grayscale(num_output_channels=IMG_CHANNELS), \n",
    "                                                                    transforms.Resize(size=(IMG_SIZE, IMG_SIZE), interpolation=Image.BILINEAR), \n",
    "                                                                    transforms.ToTensor(), \n",
    "                                                                    # transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "                                                                    transforms.Normalize(mean, std)\n",
    "                                                                    ]), \n",
    "                                                        train=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(LIDC_testset, batch_size=50, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 1/10,\tTask Weights: ['0.20', '0.20', '0.20', '0.20', '0.20']\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2394: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 16.54768\n",
      "Task 1 - Train Loss: 31.90156, Train Accuracy: 96.96%, Train Balanced Accuracy: 96.96%\n",
      "Task 2 - Train Loss: 35.12752, Train Accuracy: 51.39%, Train Balanced Accuracy: 49.86%\n",
      "Task 3 - Train Loss: 35.08484, Train Accuracy: 57.85%, Train Balanced Accuracy: 50.00%\n",
      "Task 4 - Train Loss: 57.84328, Train Accuracy: 41.99%, Train Balanced Accuracy: 49.80%\n",
      "Task 5 - Train Loss: 38.85134, Train Accuracy: 47.68%, Train Balanced Accuracy: 50.00%\n",
      "Final Output - Train Accuracy: 55.57%, Train Balanced Accuracy: 49.86%, Train F1 Score: 30.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 25.95394\n",
      "Task 1 - Test Accuracy: 100.00%, Test Balanced Accuracy: 100.00%\n",
      "Task 2 - Test Accuracy: 71.98%, Test Balanced Accuracy: 50.00%\n",
      "Task 3 - Test Accuracy: 56.90%, Test Balanced Accuracy: 50.00%\n",
      "Task 4 - Test Accuracy: 21.02%, Test Balanced Accuracy: 50.03%\n",
      "Task 5 - Test Accuracy: 48.04%, Test Balanced Accuracy: 50.00%\n",
      "Final Output - Test Accuracy: 63.07%, Test Balanced Accuracy: 50.00%\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 2/10,\tTask Weights: ['0.18', '0.19', '0.19', '0.25', '0.20']\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.85263\n",
      "Task 1 - Train Loss: 22.59399, Train Accuracy: 100.00%, Train Balanced Accuracy: 100.00%\n",
      "Task 2 - Train Loss: 20.73491, Train Accuracy: 73.47%, Train Balanced Accuracy: 50.00%\n",
      "Task 3 - Train Loss: 18.54049, Train Accuracy: 57.85%, Train Balanced Accuracy: 50.00%\n",
      "Task 4 - Train Loss: 14.95040, Train Accuracy: 25.07%, Train Balanced Accuracy: 50.48%\n",
      "Task 5 - Train Loss: 15.31349, Train Accuracy: 47.99%, Train Balanced Accuracy: 50.26%\n",
      "Final Output - Train Accuracy: 60.36%, Train Balanced Accuracy: 49.85%, Train F1 Score: 11.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 9.61602\n",
      "Task 1 - Test Accuracy: 100.00%, Test Balanced Accuracy: 100.00%\n",
      "Task 2 - Test Accuracy: 71.98%, Test Balanced Accuracy: 50.00%\n",
      "Task 3 - Test Accuracy: 56.90%, Test Balanced Accuracy: 50.00%\n",
      "Task 4 - Test Accuracy: 34.15%, Test Balanced Accuracy: 51.29%\n",
      "Task 5 - Test Accuracy: 48.23%, Test Balanced Accuracy: 50.17%\n",
      "Final Output - Test Accuracy: 57.38%, Test Balanced Accuracy: 51.10%\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 3/10,\tTask Weights: ['0.22', '0.21', '0.20', '0.18', '0.18']\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.17127\n",
      "Task 1 - Train Loss: 24.21631, Train Accuracy: 100.00%, Train Balanced Accuracy: 100.00%\n",
      "Task 2 - Train Loss: 15.93818, Train Accuracy: 73.47%, Train Balanced Accuracy: 50.00%\n",
      "Task 3 - Train Loss: 14.42712, Train Accuracy: 57.86%, Train Balanced Accuracy: 50.01%\n",
      "Task 4 - Train Loss: 11.66857, Train Accuracy: 36.30%, Train Balanced Accuracy: 51.03%\n",
      "Task 5 - Train Loss: 11.24044, Train Accuracy: 48.54%, Train Balanced Accuracy: 50.76%\n",
      "Final Output - Train Accuracy: 49.89%, Train Balanced Accuracy: 50.61%, Train F1 Score: 44.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \r"
     ]
    }
   ],
   "source": [
    "from src.training.train_ppnet import train_ppnet, test_ppnet\n",
    "from src.models.ProtoPNet import construct_PPNet\n",
    "import torch\n",
    "\n",
    "epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = construct_PPNet(base_architecture='denseFPN_121', weights='DEFAULT', img_size=100, prototype_shape=(10*5*2, 224, 1, 1), num_characteristics=5, prototype_activation_function='log', add_on_layers_type='bottleneck')\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "coefs = {\n",
    "    'crs_ent': 1,#0.4,#1.1,#0.8,#1.1,#1,#0.5,#changed from 1 at 48\n",
    "    'clst': 0.8*1.5,#0.2,#0.3,#1.1,#0.8,#5,#0.8,\n",
    "    'sep': -0.0004,#-0.0004,#-0.17,#-0.22,#-0.5, #used to be -0.08 #dm made it smaller to avoid the problem I noticed where as the separation loss is subtracted, having it too large makes your loss negative making everything explode (also -0.025 works but unstable)\n",
    "    'l1': 1e-4\n",
    "}\n",
    "\n",
    "task_weights = [1.0 / 5] * 5\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\n\" + \"-\"*100 + f\"\\nEpoch: {epoch + 1}/{epochs},\\t\" + f\"Task Weights: {[f'{weight:.2f}' for weight in task_weights]}\\n\" + \"-\"*100)\n",
    "    train_metrics,task_weights = train_ppnet(model, train_dataloader, optimizer, device, coefs=coefs, task_weights=task_weights)\n",
    "    test_metrics = test_ppnet(model, test_dataloader, device, coefs=coefs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n",
      "[7, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3]\n",
      "[2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[3, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "from src.models.backbone_models import denseNet121\n",
    "\n",
    "model = denseNet121()\n",
    "\n",
    "kernel, stride, padding = model.conv_info()\n",
    "\n",
    "print(len(kernel), len(stride), len(padding))\n",
    "print(kernel)\n",
    "print(stride)\n",
    "print(padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181 181 181\n",
      "[3, 3, 3, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from src.models.backbone_models import denseFPN_121, efficientFPN_v2_s\n",
    "\n",
    "model = efficientFPN_v2_s()\n",
    "\n",
    "kernel, stride, padding = model.conv_info()\n",
    "\n",
    "print(len(kernel), len(stride), len(padding))\n",
    "print(kernel)\n",
    "print(stride)\n",
    "print(padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 2, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 2, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 2, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3]\n",
      "[2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[3, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "from src.models.densenet_features import densenet121_features\n",
    "\n",
    "model = densenet121_features()\n",
    "\n",
    "kernel, stride, padding = model.conv_info()\n",
    "\n",
    "print(kernel)\n",
    "print(stride)\n",
    "print(padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 0, 1, 0, 1, 0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]])\n",
      "[tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), tensor([[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]]), tensor([[1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]])]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "target = [[1,1,1,1,1, 1,1,1,1,1],[1, 0, 1, 0, 1, 0, 1, 0, 1, 0], [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]]\n",
    "targets = torch.tensor(target)\n",
    "# one_hot_targets = [F.make]\n",
    "print(targets)\n",
    "one_hot_targets = [F.one_hot(t.long().squeeze()) for t in targets]\n",
    "print(one_hot_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Testing XPNet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1192\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "from src.loaders.dataloaderv2 import LIDCDataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "labels_file = './dataset/Meta/meta_info_old.csv'\n",
    "IMG_CHANNELS = 3\n",
    "IMG_SIZE = 100\n",
    "CHOSEN_CHARS = [False, False, False, True, True, False, False, True, True]\n",
    "\n",
    "# labels_file = './dataset/Meta/meta_info_old.csv'\n",
    "mean = (0.5, 0.5, 0.5)\n",
    "std = (0.5, 0.5, 0.5)\n",
    "\n",
    "# train set\n",
    "LIDC_trainset = LIDCDataset(labels_file=labels_file, chosen_chars=CHOSEN_CHARS, auto_split=True, zero_indexed=False, \n",
    "                                                        transform=transforms.Compose([transforms.Grayscale(num_output_channels=IMG_CHANNELS), \n",
    "                                                                    transforms.Resize(size=(IMG_SIZE, IMG_SIZE), interpolation=Image.BILINEAR), \n",
    "                                                                    transforms.ToTensor(), \n",
    "                                                                    # transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "                                                                    transforms.Normalize(mean, std)\n",
    "                                                                    ]),\n",
    "                                                        train=True)\n",
    "train_dataloader = torch.utils.data.DataLoader(LIDC_trainset, batch_size=10, shuffle=True, num_workers=4)\n",
    "\n",
    "LIDC_testset = LIDCDataset(labels_file=labels_file, chosen_chars=CHOSEN_CHARS, auto_split=True, zero_indexed=False, \n",
    "                                                        transform=transforms.Compose([transforms.Grayscale(num_output_channels=IMG_CHANNELS), \n",
    "                                                                    transforms.Resize(size=(IMG_SIZE, IMG_SIZE), interpolation=Image.BILINEAR), \n",
    "                                                                    transforms.ToTensor(), \n",
    "                                                                    # transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "                                                                    transforms.Normalize(mean, std)\n",
    "                                                                    ]), \n",
    "                                                        train=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(LIDC_testset, batch_size=10, shuffle=True, num_workers=4)\n",
    "\n",
    "print(len(train_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters:  8665713\n",
      "task_logits shape: [torch.Size([50, 2]), torch.Size([50, 2]), torch.Size([50, 2]), torch.Size([50, 2])]\n",
      "final_output shape: torch.Size([50, 1])\n",
      "occurance_map shape: [torch.Size([50, 20, 1, 12, 12]), torch.Size([50, 20, 1, 12, 12]), torch.Size([50, 20, 1, 12, 12]), torch.Size([50, 20, 1, 12, 12])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.utils.receptive_field import compute_proto_layer_rf_info_v2\n",
    "from src.models.ProtoPNet import PPNet, BACKBONE_DICT\n",
    "\n",
    "class XProtoNet(PPNet):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(XProtoNet, self).__init__(**kwargs)\n",
    "\n",
    "        # self.cnn_backbone = self.features\n",
    "        # del self.features\n",
    "        # cnn_backbone_out_channels = self.cnn_backbone.get_output_channels()\n",
    "\n",
    "        cnn_backbone_out_channels = self.features.get_output_channels()\n",
    "        \n",
    "        # feature extractor module\n",
    "        # self.add_on_layers = torch.nn.Sequential(*list(self.add_on_layers.children())[:-1])\n",
    "        self.add_on_layers_module = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_channels=cnn_backbone_out_channels, out_channels=self.prototype_shape[1], kernel_size=1),\n",
    "                nn.BatchNorm2d(self.prototype_shape[1]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Conv2d(in_channels=self.prototype_shape[1], out_channels=self.prototype_shape[1], kernel_size=1),\n",
    "                nn.Sigmoid()\n",
    "            ) for _ in range(self.num_characteristics)\n",
    "        ])\n",
    "        # self._initialize_weights(self.add_on_layers)\n",
    "\n",
    "        # Occurrence map module\n",
    "        self.occurrence_module = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=cnn_backbone_out_channels,\n",
    "                    out_channels=self.prototype_shape[1],\n",
    "                    kernel_size=1,\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(\n",
    "                    in_channels=self.prototype_shape[1],\n",
    "                    out_channels=self.prototype_shape[1] // 2,\n",
    "                    kernel_size=1,\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(\n",
    "                    in_channels=self.prototype_shape[1] // 2,\n",
    "                    out_channels=self.prototypes_per_characteristic,\n",
    "                    kernel_size=1,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                # nn.Conv2d(in_channels=self.prototype_shape[1], out_channels=self.prototype_shape[0], kernel_size=1, bias=False),\n",
    "            ) for _ in range(self.num_characteristics)\n",
    "        ])\n",
    "        # self._initialize_weights(self.occurrence_module)\n",
    "\n",
    "        # Last classification layer, redefine to initialize randomly\n",
    "        self.task_specific_classifier = nn.ModuleList([\n",
    "            nn.Linear(self.prototypes_per_characteristic, self.num_classes, bias=False) for _ in range(self.num_characteristics)   # Apply softmax to get confidence scores for each class of each characteristic\n",
    "        ])\n",
    "        \n",
    "        self.final_add_on_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=cnn_backbone_out_channels, out_channels=self.prototype_shape[1], kernel_size=1),\n",
    "            nn.Conv2d(in_channels=self.prototype_shape[1], out_channels=self.prototypes_per_characteristic*self.num_characteristics, kernel_size=1),\n",
    "            nn.BatchNorm2d(self.prototypes_per_characteristic*self.num_characteristics),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        \n",
    "        self.final_classifier = nn.Sequential(\n",
    "            # nn.flatten(),\n",
    "            nn.Linear(2*self.prototypes_per_characteristic*self.num_characteristics, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "            \n",
    "        \n",
    "        self._set_last_layer_incorrect_connection(incorrect_strength=0)\n",
    "\n",
    "        self.om_softmax = nn.Softmax(dim=-1)\n",
    "        self.cosine_similarity = nn.CosineSimilarity(dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feature Extractor Layer\n",
    "        x = self.features(x)\n",
    "        \n",
    "        # Hierarchical Prototype Layer\n",
    "        task_logits = []\n",
    "        similarities = []\n",
    "        occurrence_maps = []\n",
    "        for i in range(self.num_characteristics):\n",
    "            feature_map = self.add_on_layers_module[i](x).unsqueeze(1)  # shape (N, 1, 128, H, W)\n",
    "            \n",
    "            occurrence_map = self.get_occurence_map_absolute_val(x, i)  # shape (N, P, 1, H, W)\n",
    "            \n",
    "            features_extracted = (occurrence_map * feature_map).sum(dim=3).sum(dim=3)  # shape (N, P, 128)\n",
    "            \n",
    "            similarity = self.cosine_similarity(\n",
    "                features_extracted, self.prototype_vectors[i].squeeze().unsqueeze(0)\n",
    "            )  # shape (N, P)\n",
    "            similarity = (similarity + 1) / 2.0  # normalizing to [0,1] for positive reasoning\n",
    "\n",
    "            # classification layer\n",
    "            task_logit = self.task_specific_classifier[i](similarity)\n",
    "            \n",
    "            occurrence_maps.append(occurrence_map)\n",
    "            similarities.append(similarity)\n",
    "            task_logits.append(task_logit)\n",
    "        \n",
    "        # Prepare similarity vector\n",
    "        similarity_vector = torch.cat(similarities, dim=1)\n",
    "\n",
    "        # Process through final add-on layers\n",
    "        final_layer_feature_map = self.final_add_on_layers(x).squeeze()\n",
    "\n",
    "        # Concatenate all features\n",
    "        final_layer_input = torch.cat((similarity_vector, final_layer_feature_map), dim=1)\n",
    "        \n",
    "        # Final Classification Layer\n",
    "        final_output = torch.sigmoid(self.final_classifier(final_layer_input))\n",
    "\n",
    "        return final_output, task_logits, similarities, occurrence_maps\n",
    "\n",
    "    def compute_occurence_map(self, x, characteristic_index):\n",
    "        # Feature Extractor Layer\n",
    "        x = self.features(x)\n",
    "        occurrence_map = self.get_occurence_map_absolute_val(x, characteristic_index)  # shape (N, P, 1, H, W)\n",
    "        return occurrence_map\n",
    "\n",
    "    def get_occurence_map_softmaxed(self, x, characteristic_index):\n",
    "        occurrence_map = self.occurrence_module[characteristic_index](x)  # shape (N, P, H, W)\n",
    "        n, p, h, w = occurrence_map.shape\n",
    "        occurrence_map = occurrence_map.reshape((n, p, -1))\n",
    "        occurrence_map = self.om_softmax(occurrence_map).reshape((n, p, h, w)).unsqueeze(2)  # shape (N, P, 1, H, W)\n",
    "        return occurrence_map\n",
    "\n",
    "    def get_occurence_map_absolute_val(self, x, characteristic_index):\n",
    "        occurrence_map = self.occurrence_module[characteristic_index](x)  # shape (N, P, H, W)\n",
    "        occurrence_map = torch.abs(occurrence_map).unsqueeze(2)  # shape (N, P, 1, H, W)\n",
    "        return occurrence_map\n",
    "    \n",
    "    def push_forward(self, x):\n",
    "        \"\"\"\n",
    "        this method is needed for the pushing operation\n",
    "        \"\"\"\n",
    "        # Feature Extractor Layer\n",
    "        x = self.features(x)\n",
    "        \n",
    "        features_extracted_list = []\n",
    "        inverted_similarity_list = []\n",
    "        occurrence_map_list = []\n",
    "        preds_list = []\n",
    "        for characteristic_index in range(self.num_characteristics):\n",
    "            feature_map = self.add_on_layers_module[characteristic_index](x).unsqueeze(1)  # shape (N, 1, 128, H, W)\n",
    "            occurrence_map = self.get_occurence_map_absolute_val(x,characteristic_index)  # shape (N, P, 1, H, W)\n",
    "            features_extracted = (occurrence_map * feature_map).sum(dim=3).sum(dim=3)  # shape (N, P, 128)\n",
    "\n",
    "            # Prototype Layer\n",
    "            similarity = self.cosine_similarity(\n",
    "                features_extracted, self.prototype_vectors[characteristic_index].squeeze().unsqueeze(0)\n",
    "            )  # shape (N, P)\n",
    "            similarity = (similarity + 1) / 2.0  # normalizing to [0,1] for positive reasoning\n",
    "\n",
    "            # classification layer\n",
    "            logits = self.task_specific_classifier[characteristic_index](similarity)\n",
    "            preds = logits.softmax(dim=1)\n",
    "            \n",
    "            features_extracted_list.append(features_extracted)\n",
    "            inverted_similarity_list.append(1-similarity)\n",
    "            occurrence_map_list.append(occurrence_map)\n",
    "            preds_list.append(preds)\n",
    "\n",
    "        # return features_extracted, 1 - similarity, occurrence_map, logits\n",
    "        return features_extracted_list, inverted_similarity_list, occurrence_map_list, preds_list\n",
    "    \n",
    "def construct_XPNet(\n",
    "    base_architecture,\n",
    "    weights='DEFAULT',\n",
    "    img_size=100,\n",
    "    prototype_shape=(10*4*2, 128, 1, 1),\n",
    "    num_characteristics=4,\n",
    "    prototype_activation_function=\"log\",\n",
    "    add_on_layers_type=\"regular\",\n",
    "):\n",
    "    features = BACKBONE_DICT[base_architecture](weights=weights)\n",
    "    layer_filter_sizes, layer_strides, layer_paddings = features.conv_info()\n",
    "    proto_layer_rf_info = compute_proto_layer_rf_info_v2(\n",
    "        img_size=img_size,\n",
    "        layer_filter_sizes=layer_filter_sizes,\n",
    "        layer_strides=layer_strides,\n",
    "        layer_paddings=layer_paddings,\n",
    "        prototype_kernel_size=prototype_shape[2],\n",
    "    )\n",
    "    return XProtoNet(\n",
    "        features=features,\n",
    "        img_size=img_size,\n",
    "        prototype_shape=prototype_shape,\n",
    "        proto_layer_rf_info=proto_layer_rf_info,\n",
    "        num_characteristics=num_characteristics,\n",
    "        init_weights=True,\n",
    "        prototype_activation_function=prototype_activation_function,\n",
    "        add_on_layers_type=add_on_layers_type,\n",
    "    )\n",
    "# Set torch seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# model = PPNet(features=denseFPN_121(), img_size=(3, 100, 100), prototype_shape=(10*5*2, 224, 1, 1), num_characteristics=5, init_weights=True, prototype_activation_function='log', add_on_layers_type='bottleneck')\n",
    "\n",
    "model = construct_XProtoNet(base_architecture='denseFPN_121', weights='DEFAULT', img_size=100, prototype_shape=(10*4*2, 224, 1, 1), num_characteristics=4, prototype_activation_function='log', add_on_layers_type='bottleneck')\n",
    "\n",
    "# Print total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total number of parameters: \", total_params)\n",
    "\n",
    "# Create a dummy input tensor of size [50, 3, 100, 100]\n",
    "dummy_input = torch.randn(50, 3, 100, 100)\n",
    "\n",
    "# Forward pass through the model with dummy input\n",
    "final_output, task_logits, similarities, occurance_maps = model(dummy_input)\n",
    "\n",
    "# Print output shapes to verify\n",
    "print(\"task_logits shape:\", [task_logit.shape for task_logit in task_logits])  \n",
    "print(\"final_output shape:\", final_output.shape)\n",
    "print(\"occurance_map shape:\", [occurance_map.shape for occurance_map in occurance_maps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.loss.loss import (\n",
    "    CeLoss,\n",
    "    ClusterRoiFeat,\n",
    "    SeparationRoiFeat,\n",
    "    OrthogonalityLoss,\n",
    "    L_norm,\n",
    "    TransformLoss,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, recall_score, roc_auc_score\n",
    "\n",
    "\n",
    "def _adjust_weights(task_losses, exponent=2, target_sum=5):\n",
    "    \"\"\"\n",
    "    Adjusts the weights based on the task losses, using the sum of all task losses for normalization.\n",
    "    \n",
    "    Args:\n",
    "        task_losses (list): List of losses for each task.\n",
    "        exponent (int): The exponent used for calculating the inverse weights. Defaults to 2.\n",
    "        target_sum (int): The total sum to which the weights should scale. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of adjusted weights for each task.\n",
    "    \"\"\"\n",
    "    # Calculate the total sum of all task losses\n",
    "    total_loss = sum(task_losses)\n",
    "    # Normalize each loss by the total sum of losses\n",
    "    normalized_losses = [loss / total_loss for loss in task_losses] if total_loss > 0 else [0] * len(task_losses)\n",
    "    # Calculate weights using the normalized losses\n",
    "    weights = [1.0 / ((1.0 - loss) ** exponent + 1e-6) for loss in normalized_losses]\n",
    "    total_weight = sum(weights)\n",
    "    scaled_weights = [w / total_weight * target_sum for w in weights]\n",
    "    return scaled_weights\n",
    "\n",
    "def _train_or_test(model, data_loader, optimizer, device, is_train=True, use_l1_mask=True, coefs=None, task_weights=None):\n",
    "    model.to(device)\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    num_characteristics = model.num_characteristics\n",
    "    num_classes = model.num_classes\n",
    "    \n",
    "    # Initialize the loss functions\n",
    "    CrossEntropy = CeLoss(loss_weight=coefs['crs_ent'])\n",
    "    Cluster = ClusterRoiFeat(loss_weight=coefs['clst'], num_classes=num_classes)\n",
    "    Separation = SeparationRoiFeat(loss_weight=coefs['sep'], num_classes=num_classes)\n",
    "    # Orthogonality = OrthogonalityLoss(loss_weight=coefs['orth'], num_classes=num_classes)\n",
    "    Transform = TransformLoss(loss_weight=coefs['trans'])\n",
    "    L1_occ = L_norm(loss_weight=coefs['l1_occ'], mask=None, reduction=\"mean\", p=1)\n",
    "    \n",
    "    # Initialize the task losses for each characteristic\n",
    "    task_total_losses = [0.0] * num_characteristics\n",
    "    task_cross_entropy = [0.0] * num_characteristics\n",
    "    task_cluster_cost = [0.0] * num_characteristics\n",
    "    task_separation_cost = [0.0] * num_characteristics\n",
    "    task_l1 = [0.0] * num_characteristics\n",
    "    task_occ_cost = [0.0] * num_characteristics\n",
    "    task_targets_all = [[] for _ in range(num_characteristics)]\n",
    "    task_predictions_all = [[] for _ in range(num_characteristics)]\n",
    "\n",
    "    # Initialize the final output losses\n",
    "    final_total_loss = 0.0\n",
    "    final_targets_all = []\n",
    "    final_predictions_all = []\n",
    "    \n",
    "    # Initialize the total loss\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    n_batches = 0\n",
    "    context = torch.enable_grad() if is_train else torch.no_grad()\n",
    "    with context:\n",
    "        for X, targets, bweights_chars, final_target, bweight in tqdm(data_loader, leave=False):\n",
    "            X = X.to(device)\n",
    "            bweights_chars = [b.float().to(device) for b in bweights_chars]            \n",
    "            targets = [t.squeeze().to(device) for t in targets]\n",
    "            final_target = final_target.float().unsqueeze(1).to(device)\n",
    "            bweight = bweight.float().unsqueeze(1).to(device)\n",
    "            \n",
    "            final_output, task_outputs, similarities, occurrence_maps = model(X)\n",
    "            \n",
    "            ############################ Compute Losses ############################\n",
    "            \n",
    "            batch_loss = 0.0\n",
    "            for characteristic_idx, (task_output, similarity, occurrence_map, target, bweight_char) in enumerate(zip(task_outputs, similarities, occurrence_maps, targets, bweights_chars)):\n",
    "                # Get the prototype identity for the current characteristic\n",
    "                prototype_char_identity = model.prototype_class_identity[characteristic_idx].to(device)\n",
    "                \n",
    "                # Compute cross entropy cost - to encourage the correct classification of the input\n",
    "                cross_entropy_cost = CrossEntropy.compute(task_output, target)\n",
    "                \n",
    "                # Compute cluster cost - to encourage similarity among prototypes of the same class\n",
    "                cluster_cost = Cluster.compute(similarity, target)\n",
    "                \n",
    "                # Compute separation cost - to encourage diversity among prototypes of different classes\n",
    "                separation_cost = Separation.compute(similarity, target)\n",
    "                \n",
    "                # TODO: Compute Orthogonality loss - to encourage diversity among prototypes\n",
    "                \n",
    "                # Compute l1 regularization on task-specific classifier weights - to encourage sparsity in the weights\n",
    "                l1 = L_norm(loss_weight=coefs['l1'], mask=(1 - torch.t(prototype_char_identity).to(device))).compute(model.task_specific_classifier[characteristic_idx].weight)\n",
    "                \n",
    "                # Compute Occurance Map Transformation Regularization - to encourage the occurance map to be generalize better\n",
    "                occ_trans_cost = Transform.compute(X, occurrence_map, model, characteristic_idx)\n",
    "                \n",
    "                # Compute Occurance Map L1 Regularization - to make the occruance map as small as possible to avoid covering more regions than necessary\n",
    "                occ_l1 = L1_occ.compute(occurrence_map, dim=(-2, -1))\n",
    "                \n",
    "                occurance_map_cost = occ_trans_cost + occ_l1\n",
    "                \n",
    "                # Update the different task losses for each characteristic\n",
    "                task_cross_entropy[characteristic_idx] += cross_entropy_cost.item()\n",
    "                task_cluster_cost[characteristic_idx] += cluster_cost.item()\n",
    "                task_separation_cost[characteristic_idx] += separation_cost.item()\n",
    "                task_l1[characteristic_idx] += l1.item()\n",
    "                task_occ_cost[characteristic_idx] += occurance_map_cost.item()\n",
    "                \n",
    "                # Collect the different losses for each characteristic\n",
    "                task_loss = (\n",
    "                    cross_entropy_cost \n",
    "                    + cluster_cost \n",
    "                    + separation_cost \n",
    "                    + l1\n",
    "                    + occurance_map_cost\n",
    "                )\n",
    "                \n",
    "                # Update the task total losses\n",
    "                task_total_losses[characteristic_idx] += task_loss.item()\n",
    "                \n",
    "                # Apply task weights if provided\n",
    "                if task_weights:\n",
    "                    task_loss *= task_weights[characteristic_idx]\n",
    "                \n",
    "                # Update the total loss for the batch\n",
    "                batch_loss += task_loss                \n",
    "                \n",
    "                # Collect statistics for each characteristic's prediction metrics\n",
    "                preds = task_output.argmax(dim=1)\n",
    "                task_targets_all[characteristic_idx].extend(target.cpu().numpy())\n",
    "                task_predictions_all[characteristic_idx].extend(preds.detach().cpu().numpy())                \n",
    "\n",
    "            # Compute binary cross entropy loss for final output\n",
    "            final_loss = torch.nn.functional.binary_cross_entropy(final_output, final_target, weight=bweight)\n",
    "            batch_loss += final_loss\n",
    "            \n",
    "            # Collect statistics for final prediction metrics\n",
    "            final_total_loss += final_loss.item()\n",
    "            final_preds = final_output.round()\n",
    "            final_targets_all.extend(final_target.cpu().numpy())\n",
    "            final_predictions_all.extend(final_preds.detach().cpu().numpy())\n",
    "            \n",
    "            total_loss += batch_loss.item()  # Sum up total loss\n",
    "            \n",
    "            # Compute gradient and do SGD step\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            n_batches += 1\n",
    "    \n",
    "    ############################ Compute Metrics ############################\n",
    "    \n",
    "    average_loss = total_loss / n_batches\n",
    "    \n",
    "    task_losses = [t / n_batches for t in task_total_losses]\n",
    "    task_cross_entropy = [t / n_batches for t in task_cross_entropy]\n",
    "    task_cluster_cost = [t / n_batches for t in task_cluster_cost]\n",
    "    task_separation_cost = [t / n_batches for t in task_separation_cost]\n",
    "    task_l1 = [t / n_batches for t in task_l1]\n",
    "    task_occ_cost = [t / n_batches for t in task_occ_cost]\n",
    "    task_balanced_accuracies = [balanced_accuracy_score(targets, outputs) for targets, outputs in zip(task_targets_all, task_predictions_all)]\n",
    "    \n",
    "    final_loss = final_total_loss / n_batches\n",
    "    final_balanced_accuracy = balanced_accuracy_score(final_targets_all, final_predictions_all)\n",
    "    final_f1 = f1_score(final_targets_all, final_predictions_all)\n",
    "    # final_precision = precision_score(final_targets_all, final_predictions_all)\n",
    "    final_recall = recall_score(final_targets_all, final_predictions_all)\n",
    "    final_auc = roc_auc_score(final_targets_all, final_predictions_all)\n",
    "\n",
    "    # return the metrics as a dictionary\n",
    "    metrics = {'average_loss': average_loss, \n",
    "               'task_losses': task_losses,\n",
    "               'task_balanced_accuracies': task_balanced_accuracies, \n",
    "               'task_cross_entropy': task_cross_entropy,\n",
    "               'task_cluster_cost': task_cluster_cost,\n",
    "               'task_separation_cost': task_separation_cost,\n",
    "               'task_l1': task_l1,\n",
    "               'final_loss': final_loss,\n",
    "               'final_balanced_accuracy': final_balanced_accuracy,\n",
    "               'final_f1': final_f1,\n",
    "               # 'final_precision': final_precision,\n",
    "               'final_recall': final_recall,\n",
    "               'final_auc': final_auc\n",
    "            }\n",
    "    \n",
    "    if is_train:\n",
    "        task_weights = _adjust_weights(task_losses, exponent=5, target_sum=4)\n",
    "        return metrics, task_weights\n",
    "    else:\n",
    "        return metrics\n",
    "\n",
    "def train_ppnet(model, data_loader, optimizer, device, use_l1_mask=True, coefs=None, task_weights=None):\n",
    "    train_metrics, task_weights = _train_or_test(model, data_loader, optimizer, device, is_train=True, use_l1_mask=use_l1_mask, coefs=coefs, task_weights=task_weights)\n",
    "    print(\"\\nFinal Train Metrics:\")\n",
    "    print(f\"Total Loss: {train_metrics['average_loss']:.5f}\")\n",
    "    for i, (bal_acc, task_loss, task_ce, task_cc, task_sc) in enumerate(zip(train_metrics['task_balanced_accuracies'], train_metrics['task_losses'], train_metrics['task_cross_entropy'], train_metrics['task_cluster_cost'], train_metrics['task_separation_cost']), 1):\n",
    "        print(f\"Characteristic {i}      - Task Loss: {task_loss:.2f}, Cross Entropy: {task_ce:.2f}, Cluster Cost: {task_cc:.2f}, Separation Cost: {task_sc:.2f}, Balanced Accuracy: {bal_acc*100:.2f}%\")\n",
    "    # Print the metrics for the final output\n",
    "    print(f\"Malignancy Prediction - Binary Cross Entropy Loss: {train_metrics['final_loss']:.2f}, Balanced Accuracy: {train_metrics['final_balanced_accuracy']*100:.2f}%, F1 Score: {train_metrics['final_f1']*100:.2f}%\")\n",
    "    return train_metrics, task_weights\n",
    "\n",
    "def test_ppnet(model, data_loader, device, use_l1_mask=True, coefs=None, task_weights=None):\n",
    "    test_metrics = _train_or_test(model, data_loader, None, device, is_train=False, use_l1_mask=use_l1_mask, coefs=coefs, task_weights=task_weights)\n",
    "    print(\"\\nFinal Test Metrics:\")\n",
    "    print(f\"Total Loss: {test_metrics['average_loss']:.5f}\")\n",
    "    for i, (bal_acc, task_loss, task_ce, task_cc, task_sc) in enumerate(zip(test_metrics['task_balanced_accuracies'], test_metrics['task_losses'], test_metrics['task_cross_entropy'], test_metrics['task_cluster_cost'], test_metrics['task_separation_cost']), 1):\n",
    "        print(f\"Characteristic {i}      - Task Loss: {task_loss:.2f}, Cross Entropy: {task_ce:.2f}, Cluster Cost: {task_cc:.2f}, Separation Cost: {task_sc:.2f}, Balanced Accuracy: {bal_acc*100:.2f}%\")\n",
    "    # Print the metrics for the final output\n",
    "    print(f\"Malignancy Prediction - Binary Cross Entropy Loss: {test_metrics['final_loss']:.2f}, Balanced Accuracy: {test_metrics['final_balanced_accuracy']*100:.2f}%, F1 Score: {test_metrics['final_f1']*100:.2f}%\")\n",
    "    return test_metrics\n",
    "            \n",
    "def last_only(model):\n",
    "    for p in model.features.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.add_on_layers.parameters():\n",
    "        p.requires_grad = False\n",
    "    model.prototype_vectors.requires_grad = False\n",
    "    for p in model.task_specific_classifier.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in model.final_classifier.parameters():\n",
    "        p.requires_grad = True # was true\n",
    "\n",
    "def warm_only(model):\n",
    "    if model.features.encoder is not None:\n",
    "        for p in model.features.encoder.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in model.features.adaptation_layers.parameters():\n",
    "            p.requires_grad = True\n",
    "        for p in model.features.fpn.parameters():\n",
    "            p.requires_grad = True\n",
    "    else:\n",
    "        for p in model.features.parameters():\n",
    "            p.requires_grad = False\n",
    "    for p in model.add_on_layers.parameters():\n",
    "        p.requires_grad = True\n",
    "    model.prototype_vectors.requires_grad = True\n",
    "    for p in model.task_specific_classifier.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.final_classifier.parameters():\n",
    "        p.requires_grad = False\n",
    "        \n",
    "def joint(model):\n",
    "    for p in model.features.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in model.add_on_layers.parameters():\n",
    "        p.requires_grad = True\n",
    "    model.prototype_vectors.requires_grad = True\n",
    "    for p in model.task_specific_classifier.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.final_classifier.parameters():\n",
    "        p.requires_grad = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 1/1,\tTask Weights: ['1.00', '1.00', '1.00', '1.00']\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask Weights: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mweight\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mtask_weights]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m     train_metrics,task_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ppnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     test_metrics \u001b[38;5;241m=\u001b[39m test_ppnet(model, test_dataloader, device, coefs\u001b[38;5;241m=\u001b[39mcoefs)\n",
      "Cell \u001b[1;32mIn[4], line 208\u001b[0m, in \u001b[0;36mtrain_ppnet\u001b[1;34m(model, data_loader, optimizer, device, use_l1_mask, coefs, task_weights)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_ppnet\u001b[39m(model, data_loader, optimizer, device, use_l1_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, coefs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, task_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 208\u001b[0m     train_metrics, task_weights \u001b[38;5;241m=\u001b[39m \u001b[43m_train_or_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_l1_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_l1_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Train Metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 108\u001b[0m, in \u001b[0;36m_train_or_test\u001b[1;34m(model, data_loader, optimizer, device, is_train, use_l1_mask, coefs, task_weights)\u001b[0m\n\u001b[0;32m    105\u001b[0m l1 \u001b[38;5;241m=\u001b[39m L_norm(loss_weight\u001b[38;5;241m=\u001b[39mcoefs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m], mask\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mt(prototype_char_identity)\u001b[38;5;241m.\u001b[39mto(device)))\u001b[38;5;241m.\u001b[39mcompute(model\u001b[38;5;241m.\u001b[39mtask_specific_classifier[characteristic_idx]\u001b[38;5;241m.\u001b[39mweight)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Compute Occurance Map Transformation Regularization - to encourage the occurance map to be generalize better\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m occ_trans_cost \u001b[38;5;241m=\u001b[39m \u001b[43mTransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moccurrence_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcharacteristic_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Compute Occurance Map L1 Regularization - to make the occruance map as small as possible to avoid covering more regions than necessary\u001b[39;00m\n\u001b[0;32m    111\u001b[0m occ_l1 \u001b[38;5;241m=\u001b[39m L1_occ\u001b[38;5;241m.\u001b[39mcompute(occurrence_map, dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\jerem\\Desktop\\ICL-MSc\\Final_Year_Project\\FYP-interpretable-deep-learning\\2D-model\\src\\loss\\loss.py:249\u001b[0m, in \u001b[0;36mTransformLoss.compute\u001b[1;34m(self, x, occurrence_map, model, characteristic_index)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# transform input and get its new occurrence map\u001b[39;00m\n\u001b[0;32m    247\u001b[0m transformed_x \u001b[38;5;241m=\u001b[39m affine(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)  \u001b[38;5;66;03m# shape (N, D, H, W)\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m occurrence_map_transformed \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_occurence_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcharacteristic_index\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# shape (N, P, H, W)\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# transform initial occurence map\u001b[39;00m\n\u001b[0;32m    252\u001b[0m occurrence_map \u001b[38;5;241m=\u001b[39m occurrence_map\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# shape (N, P, H, W)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 127\u001b[0m, in \u001b[0;36mXProtoNet.compute_occurence_map\u001b[1;34m(self, x, characteristic_index)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_occurence_map\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, characteristic_index):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m# Feature Extractor Layer\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn_backbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     occurrence_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_occurence_map_absolute_val(x, characteristic_index)  \u001b[38;5;66;03m# shape (N, P, 1, H, W)\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m occurrence_map\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jerem\\Desktop\\ICL-MSc\\Final_Year_Project\\FYP-interpretable-deep-learning\\2D-model\\src\\models\\backbone_models.py:160\u001b[0m, in \u001b[0;36mdenseFPN_121.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    158\u001b[0m features \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m encoder \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder:\n\u001b[1;32m--> 160\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# Merge channels using 1x1 convolutions\u001b[39;00m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\densenet.py:122\u001b[0m, in \u001b[0;36m_DenseBlock.forward\u001b[1;34m(self, init_features)\u001b[0m\n\u001b[0;32m    120\u001b[0m features \u001b[38;5;241m=\u001b[39m [init_features]\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 122\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(new_features)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(features, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\densenet.py:88\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     86\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_checkpoint_bottleneck(prev_features)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m new_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(bottleneck_output)))\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\densenet.py:49\u001b[0m, in \u001b[0;36m_DenseLayer.bn_function\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbn_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m     48\u001b[0m     concated_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(inputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcated_features\u001b[49m\u001b[43m)\u001b[49m))  \u001b[38;5;66;03m# noqa: T484\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bottleneck_output\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:176\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    169\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:2512\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2510\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2513\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "coefs = {\n",
    "    'crs_ent': 1,#0.4,#1.1,#0.8,#1.1,#1,#0.5,#changed from 1 at 48\n",
    "    'clst': 0.8*1.5,#0.2,#0.3,#1.1,#0.8,#5,#0.8,\n",
    "    'sep': -0.0004,#-0.0004,#-0.17,#-0.22,#-0.5, #used to be -0.08 #dm made it smaller to avoid the problem I noticed where as the separation loss is subtracted, having it too large makes your loss negative making everything explode (also -0.025 works but unstable)\n",
    "    'l1': 1e-4,\n",
    "    'l1_occ': 1e-4,\n",
    "    'trans' : 1e-4\n",
    "}\n",
    "epochs = 1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "task_weights = [1.0] * 4\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\n\" + \"-\"*100 + f\"\\nEpoch: {epoch + 1}/{epochs},\\t\" + f\"Task Weights: {[f'{weight:.2f}' for weight in task_weights]}\\n\" + \"-\"*100)\n",
    "    train_metrics,task_weights = train_ppnet(model, train_dataloader, optimizer, device, coefs=coefs, task_weights=task_weights)\n",
    "    test_metrics = test_ppnet(model, test_dataloader, device, coefs=coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils.helpers import makedir, save_pickle\n",
    "\n",
    "def push_prototypes(\n",
    "    dataloader,  # pytorch dataloader\n",
    "    model,  # pytorch network with feature encoder and prototype vectors\n",
    "    device,\n",
    "    class_specific=True,  # enable pushing protos from only the alotted class\n",
    "    abstain_class=False,  # indicates K+1-th class is of the \"abstain\" type\n",
    "    preprocess_input_function=None,  # normalize if needed\n",
    "    root_dir_for_saving_prototypes=None,  # if not None, prototypes will be saved in this dir\n",
    "    epoch_number=None,  # if not provided, prototypes saved previously will be overwritten\n",
    "    prototype_img_filename_prefix=None,\n",
    "    prototype_self_act_filename_prefix=None,\n",
    "    proto_bound_boxes_filename_prefix=None,\n",
    "    replace_prototypes=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Search the training set for image patches that are semantically closest to\n",
    "    each learned prototype, then updates the prototypes to those image patches.\n",
    "\n",
    "    To do this, it computes the image patch embeddings (IPBs) and saves those\n",
    "    closest to the prototypes. It also saves the prototype-to-IPB distances and\n",
    "    predicted occurrence maps.\n",
    "\n",
    "    If abstain_class==True, it assumes num_classes actually equals to K+1, where\n",
    "    K is the number of real classes and 1 is the extra \"abstain\" class for\n",
    "    uncertainty estimation.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    print(f\"############## push at epoch {epoch_number} #################\")\n",
    "\n",
    "    # creating the folder (with epoch number) to save the prototypes' info and visualizations\n",
    "    if root_dir_for_saving_prototypes != None:\n",
    "        if epoch_number != None:\n",
    "            proto_epoch_dir = os.path.join(root_dir_for_saving_prototypes, \"epoch-\" + str(epoch_number))\n",
    "            makedir(proto_epoch_dir)\n",
    "        else:\n",
    "            proto_epoch_dir = root_dir_for_saving_prototypes\n",
    "    else:\n",
    "        proto_epoch_dir = None\n",
    "\n",
    "    # find the number of prototypes, and number of classes for this push\n",
    "    # prototype_shape = (model.prototypes_per_characteristic, model.prototype_shape[1], model.prototype_shape[2], model.prototype_shape[3])  # shape (P, D, 1, 1)\n",
    "    P = model.prototypes_per_characteristic\n",
    "    num_characteristics = model.num_characteristics\n",
    "    num_classes = model.num_classes\n",
    "    \n",
    "    proto_class_specific = np.full(P, class_specific)\n",
    "    \n",
    "    if abstain_class:\n",
    "        K = num_classes - 1\n",
    "        assert K >= 2, \"Abstention-push must have >= 2 classes not including abstain\"\n",
    "        # for the uncertainty prototypes, class_specific is False\n",
    "        # for now assume that each class (inc. unc.) has P_per_class == P/num_classes\n",
    "        P_per_class = P // num_classes\n",
    "        proto_class_specific[K * P_per_class : P] = False\n",
    "    else:\n",
    "        K = num_classes\n",
    "\n",
    "    # keep track of the input embedding closest to each prototype\n",
    "    proto_dist_ = [np.full(P, np.inf) for _ in range(num_characteristics)]  # saves the distances to prototypes (distance = 1-CosineSimilarities). shape (P)\n",
    "    # save some information dynamically for each prototype\n",
    "    # which are updated whenever a closer match to prototype is found\n",
    "    occurrence_map_ = [[None for _ in range(P)] for _ in range(num_characteristics)] # saves the computed occurence maps. shape (P, 1, H, W)\n",
    "    # saves the input to prototypical layer (conv feature * occurrence map), shape (P, D)\n",
    "    protoL_input_ = [[None for _ in range(P)] for _ in range(num_characteristics)]\n",
    "    # saves the input images with embeddings closest to each prototype. shape (P, 3, Ho, Wo)\n",
    "    image_ = [[None for _ in range(P)] for _ in range(num_characteristics)]\n",
    "    # saves the gt label. shape (P)\n",
    "    gt_ = [[None for _ in range(P)] for _ in range(num_characteristics)]\n",
    "    # saves the prediction logits of cases seen. shape (P, K)\n",
    "    pred_ = [[None for _ in range(P)] for _ in range(num_characteristics)]\n",
    "    # saves the filenames of cases closest to each prototype. shape (P)\n",
    "    # filename_ = [None for _ in range(P)] * num_characteristics # TODO: add filename in getitem of dataloader\n",
    "\n",
    "    # data_iter = iter(dataloader)\n",
    "    # iterator = tqdm(range(len(dataloader)), dynamic_ncols=True)\n",
    "    for X, y, _, _, _ in tqdm(dataloader, leave=False):\n",
    "        # data_sample = next(data_iter)\n",
    "        # x = data_sample[\"cine\"]  \n",
    "        \n",
    "        if preprocess_input_function is not None:\n",
    "            X = preprocess_input_function(X)\n",
    "\n",
    "        # get the network outputs for this instance\n",
    "        with torch.no_grad():\n",
    "            x = X.to(device)    # shape (B, 3, Ho, Wo)\n",
    "            (\n",
    "                protoL_input_torch,\n",
    "                proto_dist_torch,\n",
    "                occurrence_map_torch,\n",
    "                pred_torch,\n",
    "            ) = model.push_forward(x)\n",
    "            # pred_torch = logits.softmax(dim=1)\n",
    "\n",
    "        # gt = y.detach().cpu().numpy()  # shape (B)\n",
    "        image = x.detach().cpu().numpy()  # shape (B, 3, Ho, Wo)\n",
    "        # filename = data_sample[\"filename\"]  # shape (B) \n",
    "        \n",
    "        for characteristic_idx in range(num_characteristics):\n",
    "            proto_class_identity = np.argmax(model.prototype_class_identity[characteristic_idx].cpu().numpy(), axis=1)  # shape (P)\n",
    "            # record down batch data as numpy arrays\n",
    "            gt = y[characteristic_idx].detach().cpu().numpy()\n",
    "            protoL_input = protoL_input_torch[characteristic_idx].detach().cpu().numpy()\n",
    "            proto_dist = proto_dist_torch[characteristic_idx].detach().cpu().numpy()\n",
    "            occurrence_map = occurrence_map_torch[characteristic_idx].detach().cpu().numpy()\n",
    "            pred = pred_torch[characteristic_idx].detach().cpu().numpy()\n",
    "\n",
    "            # for each prototype, find the minimum distance and their indices\n",
    "            for prototype_idx in range(P):\n",
    "                proto_dist_j = proto_dist[:, prototype_idx]  # (B)\n",
    "                if proto_class_specific[prototype_idx]:\n",
    "                    # compare with only the images of the prototype's class\n",
    "                    proto_dist_j = np.ma.masked_array(proto_dist_j, gt != proto_class_identity[prototype_idx])\n",
    "                    if proto_dist_j.mask.all():\n",
    "                        # if none of the classes this batch are the class of interest, move on\n",
    "                        continue\n",
    "                proto_dist_j_min = np.amin(proto_dist_j)  # scalar\n",
    "\n",
    "                # if the distance this batch is smaller than prev.best, save it\n",
    "                if proto_dist_j_min <= proto_dist_[characteristic_idx][prototype_idx]:\n",
    "                    a = np.argmin(proto_dist_j)\n",
    "                    \n",
    "                    proto_dist_[characteristic_idx][prototype_idx] = proto_dist_j_min\n",
    "                    protoL_input_[characteristic_idx][prototype_idx] = protoL_input[a, prototype_idx]\n",
    "                    occurrence_map_[characteristic_idx][prototype_idx] = occurrence_map[a, prototype_idx]\n",
    "                    pred_[characteristic_idx][prototype_idx] = pred[a]\n",
    "                    image_[characteristic_idx][prototype_idx] = image[a]\n",
    "                    gt_[characteristic_idx][prototype_idx] = gt[a]\n",
    "                    # filename_[characteristic_idx][prototype_idx] = filename[a]\n",
    "\n",
    "    prototypes_similarity_to_src_ROIs = 1 - np.array(proto_dist_)  # invert distance to similarity  shape (P)\n",
    "    prototypes_occurrence_maps = np.array(occurrence_map_)  # shape (P, 1, H, W)\n",
    "    prototypes_src_imgs = np.array(image_)  # shape (P, 3, Ho, Wo)\n",
    "    prototypes_gts = np.array(gt_)  # shape (P)\n",
    "    prototypes_preds = np.array(pred_)  # shape (P, K)\n",
    "    # prototypes_filenames = np.array(filename_)  # shape (P)\n",
    "\n",
    "    # save the prototype information in a pickle file\n",
    "    prototype_data_dict = {\n",
    "        # \"prototypes_filenames\": prototypes_filenames,\n",
    "        \"prototypes_src_imgs\": prototypes_src_imgs,\n",
    "        \"prototypes_gts\": prototypes_gts,\n",
    "        \"prototypes_preds\": prototypes_preds,\n",
    "        \"prototypes_occurrence_maps\": prototypes_occurrence_maps,\n",
    "        \"prototypes_similarity_to_src_ROIs\": prototypes_similarity_to_src_ROIs,\n",
    "    }\n",
    "    save_pickle(prototype_data_dict, f\"{proto_epoch_dir}/prototypes_info.pickle\")\n",
    "\n",
    "    if replace_prototypes:\n",
    "        protoL_input_ = np.array(protoL_input_)\n",
    "        print(\"\\tExecuting push ...\")\n",
    "        \n",
    "        for idx, (prototype_vectors, protoL_input_char) in enumerate(zip(model.prototype_vectors, protoL_input_)):\n",
    "            prototype_update = np.reshape(protoL_input_char, prototype_vectors.shape)\n",
    "            with torch.no_grad():\n",
    "                prototype_vectors.data.copy_(torch.tensor(prototype_update, dtype=torch.float32).to(device))\n",
    "            \n",
    "        # prototype_update = np.reshape(protoL_input_, tuple(prototype_shape))\n",
    "        # model.prototype_vectors.data.copy_(torch.tensor(prototype_update, dtype=torch.float32).cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## push at epoch 1 #################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1192 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'None/prototypes_info.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mpush_prototypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43mclass_specific\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpreprocess_input_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[43mroot_dir_for_saving_prototypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepoch_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                \u001b[49m\u001b[43mreplace_prototypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 157\u001b[0m, in \u001b[0;36mpush_prototypes\u001b[1;34m(dataloader, model, device, class_specific, abstain_class, preprocess_input_function, root_dir_for_saving_prototypes, epoch_number, prototype_img_filename_prefix, prototype_self_act_filename_prefix, proto_bound_boxes_filename_prefix, replace_prototypes)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# prototypes_filenames = np.array(filename_)  # shape (P)\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# save the prototype information in a pickle file\u001b[39;00m\n\u001b[0;32m    149\u001b[0m prototype_data_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;66;03m# \"prototypes_filenames\": prototypes_filenames,\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprototypes_src_imgs\u001b[39m\u001b[38;5;124m\"\u001b[39m: prototypes_src_imgs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprototypes_similarity_to_src_ROIs\u001b[39m\u001b[38;5;124m\"\u001b[39m: prototypes_similarity_to_src_ROIs,\n\u001b[0;32m    156\u001b[0m }\n\u001b[1;32m--> 157\u001b[0m \u001b[43msave_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprototype_data_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mproto_epoch_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/prototypes_info.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m replace_prototypes:\n\u001b[0;32m    160\u001b[0m     protoL_input_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(protoL_input_)\n",
      "File \u001b[1;32mc:\\Users\\jerem\\Desktop\\ICL-MSc\\Final_Year_Project\\FYP-interpretable-deep-learning\\2D-model\\src\\utils\\helpers.py:142\u001b[0m, in \u001b[0;36msave_pickle\u001b[1;34m(pickle_data, pickle_path, log)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_pickle\u001b[39m(pickle_data, pickle_path, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mprint\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpickle_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m    143\u001b[0m         pickle\u001b[38;5;241m.\u001b[39mdump(pickle_data, handle, protocol\u001b[38;5;241m=\u001b[39mpickle\u001b[38;5;241m.\u001b[39mHIGHEST_PROTOCOL)\n\u001b[0;32m    144\u001b[0m         log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata successfully saved in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpickle_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'None/prototypes_info.pickle'"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "push_prototypes(train_dataloader, \n",
    "                model, \n",
    "                device=device,\n",
    "                class_specific=True, \n",
    "                preprocess_input_function=None, \n",
    "                root_dir_for_saving_prototypes=None,\n",
    "                epoch_number=1,\n",
    "                replace_prototypes=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters:  12060009\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "from src.models.backbone_models import denseNet121, denseNet169, resNet152, resNet34, vgg16, vgg19, denseFPN_121\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "from efficientnet_pytorch_3d import EfficientNet3D\n",
    "model = EfficientNet3D.from_name(\"efficientnet-b3\", in_channels=1, override_params={'num_classes': 1})\n",
    "# model = EfficientNet3D.from_name(\"efficientnet-b0\", override_params={'num_classes': 1}, in_channels=1).extract_features\n",
    "# model = nn.Sequential(*list(model.children())[:-1])\n",
    "\n",
    "# print number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total number of parameters: \", total_params)\n",
    "\n",
    "dummy_input = torch.randn(1, 1, 128, 128, 128)\n",
    "\n",
    "features = model(dummy_input)\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method EfficientNet3D.extract_features of EfficientNet3D(\n",
       "  (_conv_stem): Conv3dStaticSamePadding(\n",
       "    1, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d((0, 1, 0, 1, 0, 1))\n",
       "  )\n",
       "  (_bn0): BatchNorm3d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock3D(\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3, 3), stride=[2, 2, 2], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3, 3), stride=[2, 2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5, 5), stride=[2, 2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 2, 1, 2, 1, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3, 3), stride=[2, 2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6-7): 2 x MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5, 5), stride=[1, 1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9-10): 2 x MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5, 5), stride=[2, 2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 2, 1, 2, 1, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12-14): 3 x MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3, 3), stride=[1, 1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv3dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm3d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=1, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program_Files\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'EfficientNet3d' from 'src.models.backbone_models' (c:\\Users\\jerem\\Desktop\\ICL-MSc\\Final_Year_Project\\FYP-interpretable-deep-learning\\2D-model\\src\\models\\backbone_models.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackbone_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m denseNet121, denseNet169, resNet152, resNet34, vgg16, vgg19, denseFPN_121, efficientNet3D, EfficientNet3d\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m EfficientNet3d\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'EfficientNet3d' from 'src.models.backbone_models' (c:\\Users\\jerem\\Desktop\\ICL-MSc\\Final_Year_Project\\FYP-interpretable-deep-learning\\2D-model\\src\\models\\backbone_models.py)"
     ]
    }
   ],
   "source": [
    "from src.models.backbone_models import denseNet121, denseNet169, resNet152, resNet34, vgg16, vgg19, denseFPN_121, EfficeientNet3d\n",
    "import torch \n",
    "\n",
    "model = EfficientNet3d\n",
    "\n",
    "# print number of parameters\n",
    "# total_params = sum(p.numel() for p in model.parameters())\n",
    "# print(\"Total number of parameters: \", total_params)\n",
    "\n",
    "dummy_input = torch.randn(1, 1, 128, 128, 128)\n",
    "\n",
    "features = model(dummy_input)\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet3D(\n",
       "  (_conv_stem): Conv3dStaticSamePadding(\n",
       "    1, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d((0, 1, 0, 1, 0, 1))\n",
       "  )\n",
       "  (_bn0): BatchNorm3d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock3D(\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3, 3), stride=[2, 2, 2], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3, 3), stride=[2, 2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5, 5), stride=[2, 2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 2, 1, 2, 1, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3, 3), stride=[2, 2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6-7): 2 x MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5, 5), stride=[1, 1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9-10): 2 x MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5, 5), stride=[2, 2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 2, 1, 2, 1, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12-14): 3 x MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3, 3), stride=[1, 1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv3dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm3d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=1, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv3dStaticSamePadding(\n",
       "    1, 40, kernel_size=(3, 3, 3), stride=(2, 2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d((0, 1, 0, 1, 0, 1))\n",
       "  )\n",
       "  (1): BatchNorm3d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): ModuleList(\n",
       "    (0): MBConvBlock3D(\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        40, 40, kernel_size=(3, 3, 3), stride=[2, 2, 2], groups=40, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        40, 10, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        10, 40, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        40, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock3D(\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=24, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        24, 6, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        6, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        24, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3, 3), stride=[2, 2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        144, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3-4): 2 x MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        192, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        192, 192, kernel_size=(5, 5, 5), stride=[2, 2, 2], groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 2, 1, 2, 1, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        192, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6-7): 2 x MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        288, 288, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        288, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        288, 288, kernel_size=(3, 3, 3), stride=[2, 2, 2], groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        288, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9-12): 4 x MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        96, 576, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        576, 576, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=576, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        576, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        24, 576, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        576, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        96, 576, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        576, 576, kernel_size=(5, 5, 5), stride=[1, 1, 1], groups=576, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        576, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        24, 576, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        576, 136, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14-17): 4 x MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        136, 816, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        816, 816, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=816, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        816, 34, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        34, 816, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        816, 136, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (18): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        136, 816, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        816, 816, kernel_size=(5, 5, 5), stride=[2, 2, 2], groups=816, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 2, 1, 2, 1, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        816, 34, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        34, 816, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        816, 232, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (19-23): 5 x MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        232, 1392, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        1392, 1392, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=1392, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        1392, 58, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        58, 1392, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        1392, 232, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (24): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        232, 1392, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        1392, 1392, kernel_size=(3, 3, 3), stride=[1, 1, 1], groups=1392, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        1392, 58, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        58, 1392, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        1392, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (25): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        384, 2304, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        2304, 2304, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=2304, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        2304, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        96, 2304, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        2304, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (3): Conv3dStaticSamePadding(\n",
       "    384, 1536, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (4): BatchNorm3d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Sequential(*list(model.children())[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method EfficientNet3D.extract_features of EfficientNet3D(\n",
       "  (_conv_stem): Conv3dStaticSamePadding(\n",
       "    1, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d((0, 1, 0, 1, 0, 1))\n",
       "  )\n",
       "  (_bn0): BatchNorm3d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock3D(\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3, 3), stride=[2, 2, 2], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3, 3), stride=[2, 2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5, 5), stride=[2, 2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 2, 1, 2, 1, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3, 3), stride=[2, 2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6-7): 2 x MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5, 5), stride=[1, 1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9-10): 2 x MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5, 5), stride=[2, 2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 2, 1, 2, 1, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12-14): 3 x MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3, 3), stride=[1, 1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv3dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm3d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mefficientnet_pytorch_3d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EfficientNet3D\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m EfficientNet3D\u001b[38;5;241m.\u001b[39mfrom_name(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mefficientnet-b0\u001b[39m\u001b[38;5;124m\"\u001b[39m, override_params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m}, in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[43mdevice\u001b[49m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchsummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[0;32m      7\u001b[0m summary(model, input_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, 200, 200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ResNetFeatureMapsExtractor(\n",
       "    (m): SequentialMultiOutput(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PanopticFPN(\n",
       "    (0): Parallel(\n",
       "      (0-1): 2 x Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (4): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): Parallel(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Interpolate()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Interpolate()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Interpolate()\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Interpolate()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Interpolate()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Interpolate()\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Interpolate()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Interpolate()\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Interpolate()\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Interpolate()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sum()\n",
       "    (3): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (2): Interpolate()\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Sequential(*list(model.children())[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (9): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.features\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "nn.Sequential(*list(model.features)[:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
